
            <!DOCTYPE html>
            <html lang="zh-CN">
                <head>
                    <meta charset="UTF-8">
                    <title>
 FFmpeg获取DirectShow设备数据（摄像头，录屏） - CSDN博客
</title>

                <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/detail-60a2c245da.min.css">
                <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/themes/skin3-template/skin3-template-88717cedf2.min.css">

                <script type="text/javascript">
                var username = "";
                </script>

                <script src="https://csdnimg.cn/public/common/libs/jquery/jquery-1.9.1.min.js" type="text/javascript"></script>

                <!-- 新版上报 -->
                <!-- 新版上报end -->
                <link rel="stylesheet" href="https://csdnimg.cn/public/sandalstrap/1.3/css/sandalstrap.min.css"> 
                </head>
                <body>    
        
                    <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/blog_code-c3a0c33d5c.css">
                    <div class="container clearfix pt0" id="mainBox">
        <main style="width: 100%;"><div class="blog-content-box">
 <div class="article-title-box" id="article_anchors_163">
  <span class="article-type type-1 float-left">
   原
  </span>
  <h1 class="title-article">
   FFmpeg获取DirectShow设备数据（摄像头，录屏）
  </h1>
 </div>
 <div class="article-info-box">
  <div class="article-bar-top d-flex">
   <span class="time">
    2014年08月02日 00:57:27
   </span>
   <div ">
    <span class="read-count">
     阅读数：89389
    </span>
   </div>
  </div>
 </div>
 <article>
  <div class="article_content clearfix csdn-tracking-statistics" data-dsm="post" data-mod="popu_307" data-pid="blog" id="article_content">
   <link href="https://csdnimg.cn/release/phoenix/template/css/htmledit_views-0a60691e80.css" rel="stylesheet"/>
   <div class="htmledit_views">
    <p>
     这两天研究了FFmpeg获取DirectShow设备数据的方法，在此简单记录一下以作备忘。本文所述的方法主要是对应Windows平台的。
    </p>
    <h2>
     <strong>
      1.       列设备
     </strong>
    </h2>
    <div>
     <p align="center">
     </p>
     <pre class="plain">ffmpeg -list_devices true -f dshow -i dummy</pre>
     <p>
     </p>
    </div>
    <p>
     命令执行后输出的结果如下（注：中文的设备会出现乱码的情况）。列表显示设备的名称很重要，输入的时候都是使用“-f dshow -i video="{设备名}"”的方式。
    </p>
    <p style="text-align:center;">
     <img alt="" src="https://img-blog.csdn.net/20140730013108120"/>
     <br/>
    </p>
    <p>
     我自己的机器上列出了以下设备：
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">[dshow @0388f5e0] DirectShow video devices
[dshow @0388f5e0]  "Integrated Camera"
[dshow @0388f5e0] "screen-capture-recorder"
[dshow @0388f5e0] DirectShow audio devices
[dshow @0388f5e0]  "鍐呰楹﹀厠椋?(Conexant20672 SmartAudi"
[dshow @0388f5e0]  "virtual-audio-capturer"</pre>
     <p>
     </p>
    </div>
    <p>
     下文的测试中，使用其中的两个视频输入："Integrated Camera"和"screen-capture-recorder"。
    </p>
    <p>
     注：音频设备出现乱码，这个问题的解决方法会随后提到。
    </p>
    <h2>
     <strong>
      2.       获取摄像头数据（保存为本地文件或者发送实时流）
     </strong>
    </h2>
    <h4>
     2.1. 编码为H.264，保存为本地文件
    </h4>
    <p>
     下面这条命令，实现了从摄像头读取数据并编码为H.264，最后保存成mycamera.mkv。
    </p>
    <div>
     <p align="center">
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="Integrated Camera" -vcodec libx264 mycamera.mkv</pre>
    </div>
    <h4>
     2.2. 直接播放摄像头的数据
    </h4>
    <p>
     使用ffplay可以直接播放摄像头的数据，命令如下：
    </p>
    <div>
     <p align="center">
     </p>
     <pre class="plain">ffplay -f dshow -i video="Integrated Camera"</pre>
     <p>
     </p>
    </div>
    <p style="text-align:left;">
     如果设备名称正确的话，会直接打开本机的摄像头，如图所示。
    </p>
    <p style="text-align:center;">
     <img alt="" src="https://img-blog.csdn.net/20140730012916906?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"/>
     <br/>
    </p>
    <p style="text-align:left;">
     注：除了使用DirectShow作为输入外，使用VFW也可以读取到摄像头的数据，例如下述命令可以播放摄像头数据：
    </p>
    <p style="text-align:left;">
    </p>
    <pre class="plain">ffplay -f vfwcap -i 0</pre>
    <p>
    </p>
    <p>
     此外，可以使用FFmpeg的list_options查看设备的选项：
    </p>
    <p>
    </p>
    <pre class="plain">ffmpeg -list_options true -f dshow -i video="Integrated Camera"</pre>
    <br/>
    输出如下：
    <p>
    </p>
    <p>
    </p>
    <pre class="plain">[dshow @ 03845420] DirectShow video device options
[dshow @ 03845420]  Pin "鎹曡幏"
[dshow @ 03845420]   pixel_format=bgr24  min s=640x480 fps=15 max s=640x480 fps=30
[dshow @ 03845420]   pixel_format=bgr24  min s=640x360 fps=15 max s=640x360 fps=30
[dshow @ 03845420]   pixel_format=bgr24  min s=352x288 fps=15 max s=352x288 fps=30
[dshow @ 03845420]   pixel_format=bgr24  min s=320x240 fps=15 max s=320x240 fps=30
[dshow @ 03845420]   pixel_format=bgr24  min s=800x448 fps=1 max s=800x448 fps=15
[dshow @ 03845420]   pixel_format=bgr24  min s=960x544 fps=1 max s=960x544 fps=10
[dshow @ 03845420]   pixel_format=bgr24  min s=1280x720 fps=1 max s=1280x720 fps=10
[dshow @ 03845420]   pixel_format=bgr24  min s=424x240 fps=15 max s=424x240 fps=30
[dshow @ 03845420]   pixel_format=yuyv422  min s=640x480 fps=15 max s=640x480 fps=30
[dshow @ 03845420]   pixel_format=yuyv422  min s=640x360 fps=15 max s=640x360 fps=30
[dshow @ 03845420]   pixel_format=yuyv422  min s=352x288 fps=15 max s=352x288 fps=30
[dshow @ 03845420]   pixel_format=yuyv422  min s=320x240 fps=15 max s=320x240 fps=30
[dshow @ 03845420]   pixel_format=yuyv422  min s=800x448 fps=1 max s=800x448 fps=15
[dshow @ 03845420]   pixel_format=yuyv422  min s=960x544 fps=1 max s=960x544 fps=10
[dshow @ 03845420]   pixel_format=yuyv422  min s=1280x720 fps=1 max s=1280x720 fps=10
[dshow @ 03845420]   pixel_format=yuyv422  min s=424x240 fps=15 max s=424x240 fps=30
[dshow @ 03845420]   vcodec=mjpeg  min s=640x480 fps=15 max s=640x480 fps=30
[dshow @ 03845420]   vcodec=mjpeg  min s=640x360 fps=15 max s=640x360 fps=30
[dshow @ 03845420]   vcodec=mjpeg  min s=352x288 fps=15 max s=352x288 fps=30
[dshow @ 03845420]   vcodec=mjpeg  min s=320x240 fps=15 max s=320x240 fps=30
[dshow @ 03845420]   vcodec=mjpeg  min s=800x448 fps=15 max s=800x448 fps=30
[dshow @ 03845420]   vcodec=mjpeg  min s=960x544 fps=15 max s=960x544 fps=30
[dshow @ 03845420]   vcodec=mjpeg  min s=1280x720 fps=15 max s=1280x720 fps=30</pre>
    <p>
     <br/>
    </p>
    <p>
     可以通过输出信息设置摄像头的参数。
    </p>
    <p>
     例如，设置摄像头分辨率为1280x720
    </p>
    <p>
    </p>
    <pre class="plain">ffplay -s 1280x720 -f dshow -i video="Integrated Camera"</pre>
    设置分辨率为424x240
    <p>
    </p>
    <p>
    </p>
    <pre class="plain">ffplay -s 424x240 -f dshow -i video="Integrated Camera"</pre>
    <br/>
    <p>
    </p>
    <h4>
     2.3. 编码为H.264，发布UDP
    </h4>
    <p>
     下面这条命令，实现了：获取摄像头数据-&gt;编码为H.264-&gt;封装为UDP并发送至组播地址。
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="Integrated Camera" -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f h264 udp://233.233.233.223:6666</pre>
     <p>
     </p>
    </div>
    <p>
     注1：考虑到提高libx264的编码速度，添加了-preset:v ultrafast和-tune:v zerolatency两个选项。
    </p>
    <p>
     注2：高分辨率的情况下，使用UDP可能出现丢包的情况。为了避免这种情况，可以添加–s 参数（例如-s 320x240）调小分辨率。
    </p>
    <h4>
     2.4. 编码为H.264，发布RTP
    </h4>
    <p>
     下面这条命令，实现了：获取摄像头数据-&gt;编码为H.264-&gt;封装为RTP并发送至组播地址。
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="Integrated Camera" -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f rtp rtp://233.233.233.223:6666&gt;test.sdp</pre>
     <p>
     </p>
    </div>
    <p>
     注1：考虑到提高libx264的编码速度，添加了-preset:v ultrafast和-tune:v zerolatency两个选项。
    </p>
    <p>
     注2：结尾添加“&gt;test.sdp”可以在发布的同时生成sdp文件。该文件可以用于该视频流的播放。
    </p>
    <h4>
     2.5. 编码为H.264，发布RTMP
    </h4>
    <p>
     下面这条命令，实现了：获取摄像头数据-&gt;编码为H.264-&gt;并发送至RTMP服务器。
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="Integrated Camera" -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f flv rtmp://localhost/oflaDemo/livestream</pre>
     <br/>
     <p>
     </p>
    </div>
    <h4>
     2.6. 编码为MPEG2，发布UDP
    </h4>
    <p>
     与编码为H.264类似，指明-vcodec即可。
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="Integrated Camera" -vcodec mpeg2video -f mpeg2video udp://233.233.233.223:6666</pre>
     <br/>
     <p>
     </p>
    </div>
    <p>
     播放MPEG2的UDP流如下。指明-vcodec为mpeg2video即可
    </p>
    <div>
     <p align="center">
     </p>
     <pre class="plain">ffplay -vcodec mpeg2video udp://233.233.233.223:6666</pre>
     <p>
     </p>
    </div>
    <p>
    </p>
    <h2>
     <strong>
      3.       屏幕录制（Windows平台下保存为本地文件或者发送实时流）
     </strong>
    </h2>
    <p>
     Linux下使用FFmpeg进行屏幕录制相对比较方便，可以使用x11grab，使用如下的命令：
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f x11grab -s 1600x900 -r 50 -vcodec libx264 –preset:v ultrafast –tune:v zerolatency -crf 18 -f mpegts udp://localhost:1234</pre>
     <p>
     </p>
    </div>
    <p>
     详细时使用方式可以参考这篇文章：
     <a href="http://www.waitwut.info/blog/2013/06/09/desktop-streaming-with-ffmpeg-for-lower-latency/">
      DesktopStreaming With FFmpeg for Lower Latency
     </a>
    </p>
    <p>
     Linux录屏在这里不再赘述。在Windows平台下屏幕录像则要稍微复杂一些。在Windows平台下，使用-dshow取代x11grab。一句话介绍：注册录屏dshow滤镜（例如screen-capture-recorder），然后通过dshow获取录屏图像然后编码处理。
    </p>
    <p>
     因此，在使用FFmpeg屏幕录像之前，需要先安装dshow滤镜。在这里推荐一个软件：screen capture recorder。安装这个软件之后，就可以通过FFmpeg屏幕录像了。
    </p>
    <p>
    </p>
    <p>
     screen capture recorder项目主页：
    </p>
    <p>
     <a href="http://sourceforge.net/projects/screencapturer/">
      http://sourceforge.net/projects/screencapturer/
     </a>
    </p>
    <p>
     下载地址：
    </p>
    <p>
     <a href="http://sourceforge.net/projects/screencapturer/files">
      http://sourceforge.net/projects/screencapturer/files
     </a>
    </p>
    <p>
     下载完后，一路“Next”即可安装完毕。注意，需要Java运行环境（Java Runtime Environment），如果没有的话下载一个就行。
    </p>
    <p>
     screen capture recorder本身就可以录屏，不过这里我们使用FFmpeg进行录屏。
    </p>
    <p style="text-align:center;">
     <img alt="" src="https://img-blog.csdn.net/20140730013631727?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"/>
     <br/>
    </p>
    <h4>
     3.1. 编码为H.264，保存为本地文件
    </h4>
    <p>
     下面的命令可以将屏幕录制后编码为H.264并保存为本地文件。
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="screen-capture-recorder" -r 5 -vcodec libx264 -preset:v ultrafast -tune:v zerolatency MyDesktop.mkv</pre>
     <p>
     </p>
    </div>
    <p>
     注：“-r 5”的意思是把帧率设置成5。
    </p>
    <p>
     最后得到的效果如下图。
    </p>
    <p style="text-align:center;">
     <img alt="" src="https://img-blog.csdn.net/20140730013701321?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"/>
     <br/>
    </p>
    <p>
     此外，也可以录声音，声音输入可以分成两种：一种是真人说话的声音，通过话筒输入；一种是虚拟的声音，即录屏的时候电脑耳机里的声音。下面两条命令可以分别录制话筒的声音和电脑耳机里的声音。
    </p>
    <p>
     录屏，伴随话筒输入的声音
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="screen-capture-recorder" -f dshow -i audio="鍐呰楹﹀厠椋?(Conexant 20672 SmartAudi" -r 5 -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -acodec libmp3lame MyDesktop.mkv</pre>
     <p>
     </p>
    </div>
    <p>
     上述命令有问题：audio那里有乱码，把乱码ANSI转UTF-8之后，开始测试不行，后来发现是自己疏忽大意，乱码部分转码后为“内装麦克风 ”，然后接可以正常使用了。因此，命令应该如下图所示：
    </p>
    <p>
    </p>
    <pre class="plain">ffmpeg -f dshow -i video="screen-capture-recorder" -f dshow -i audio="内装麦克风 (Conexant 20672 SmartAudi" -r 5 -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -acodec libmp3lame MyDesktop.mkv</pre>
    注：
    <p>
    </p>
    <p>
     如果不熟悉ANSI转码UTF-8的话，还有一种更简单的方式查看设备的名称。即不使用FFmpeg查看系统DirectShow输入设备的名称，而使用DirectShow SDK自带的工具GraphEdit（或者网上下一个GraphStudioNext）查看输入名称。
    </p>
    <p>
     打开GraphEdit选择“图像-&gt;插入滤镜”
    </p>
    <p style="text-align:center;">
     <img alt="" src="https://img-blog.csdn.net/20140921214014292?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"/>
     <br/>
    </p>
    <p>
     然后就可以通过查看Audio Capture Sources来查看音频输入设备的简体中文名称了。从图中可以看出是“内装麦克风 (Conexant 20672 SmartAudi”。
    </p>
    <p style="text-align:center;">
     <img alt="" src="https://img-blog.csdn.net/20140921214115616?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast"/>
     <br/>
    </p>
    <p>
     PS：感觉这条命令适合做讲座之类的时候使用
    </p>
    <p>
    </p>
    <p>
     录屏，伴随耳机输入的声音
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="screen-capture-recorder" -f dshow -i audio="virtual-audio-capturer" -r 5 -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -acodec libmp3lame MyDesktop.mkv</pre>
     <p>
     </p>
    </div>
    <p>
     PS：测这条命令的时候，这在听歌，因此录制的视频中的音频就是那首歌曲。
    </p>
    <p>
    </p>
    <h4>
     3.2. 编码为H.264，发布UDP
    </h4>
    <p>
     下面的命令可以将屏幕录制后编码为H.264并封装成UDP发送到组播地址
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="screen-capture-recorder" -r 5 -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f h264 udp://233.233.233.223:6666</pre>
     <p>
     </p>
    </div>
    <p>
     注1：考虑到提高libx264的编码速度，添加了-preset:v ultrafast和-tune:v zerolatency两个选项。
    </p>
    <p>
     注2：高分辨率的情况下，使用UDP可能出现丢包的情况。为了避免这种情况，可以添加–s 参数（例如-s 320x240）调小分辨率。
    </p>
    <h4>
     3.3. 编码为H.264，发布RTP
    </h4>
    <p>
     下面的命令可以将屏幕录制后编码为H.264并封装成RTP并发送到组播地址
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="screen-capture-recorder" -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f rtp rtp://233.233.233.223:6666&gt;test.sdp</pre>
     <p>
     </p>
    </div>
    <p>
     注1：考虑到提高libx264的编码速度，添加了-preset:v ultrafast和-tune:v zerolatency两个选项。
    </p>
    <p>
     注2：结尾添加“&gt;test.sdp”可以在发布的同时生成sdp文件。该文件可以用于该视频流的播放。如下命令即可播放：
    </p>
    <div>
     <p align="center">
     </p>
     <pre class="plain">ffplay test.sdp</pre>
     <p>
     </p>
    </div>
    <h4>
     3.4. 编码为H.264，发布RTMP
    </h4>
    <p>
     原理同上，不再赘述。
    </p>
    <div>
     <p>
     </p>
     <pre class="plain">ffmpeg -f dshow -i video="Integrated Camera" -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f flv rtmp://localhost/oflaDemo/livestream</pre>
     <p>
     </p>
    </div>
    <p>
     注意：播放RTMP的时候，-max_delay参数会比较明显的影响延迟，将此参数值设定小一些，有利于降低延时。
    </p>
    <div>
     <p align="center">
     </p>
     <pre class="plain">ffplay -max_delay 100000 "rtmp://localhost/oflaDemo/livestream live=1"</pre>
    </div>
    <div>
     <br/>
    </div>
    <h2>
     4.另一种屏幕录制的方式（2014.10.1更新）
    </h2>
    <div>
     最近发现FFmpeg还有一个专门用于Windows下屏幕录制的设备：gdigrab。
    </div>
    <div>
     gdigrab是基于GDI的抓屏设备，可以用于抓取屏幕的特定区域。在这里记录一下gdigrab的用法。
    </div>
    <div>
     gdigrab通过设定不同的输入URL，支持两种方式的屏幕抓取：
    </div>
    <div>
     （1）“desktop”：抓取整张桌面。或者抓取桌面中的一个特定的区域。
     <br/>
     （2）“title={窗口名称}”：抓取屏幕中特定的一个窗口。
     <br/>
    </div>
    <div>
     下面举几个例子。
    </div>
    <div>
     最简单的抓屏：
    </div>
    <div>
     <pre class="plain">ffmpeg -f gdigrab -i desktop out.mpg</pre>
     <br/>
     从屏幕的（10,20）点处开始，抓取640x480的屏幕，设定帧率为5
    </div>
    <div>
     <pre class="plain">ffmpeg -f gdigrab -framerate 5 -offset_x 10 -offset_y 20 -video_size 640x480 -i desktop out.mpg</pre>
     <br/>
     <br/>
    </div>
    <div>
     <p>
     </p>
    </div>
   </div>
  </div>
  <div style="display:none;" class="hide-article-box text-center csdn-tracking-statistics tracking-click" data-mod="popu_376">
   <a class="btn btn-red-hollow" id="btn-readmore">
    阅读更多
   </a>
  </div>
 </article>
 <div class="article-bar-bottom">
  <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许不得转载。			https://blog.csdn.net/leixiaohua1020/article/details/38284961
  </div>
  <div class="tags-box artic-tag-box">
   <span class="label">
    文章标签：
   </span>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=ffmpeg&amp;t=blog" target="_blank">
    ffmpeg
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=directshow&amp;t=blog" target="_blank">
    directshow
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=录屏&amp;t=blog" target="_blank">
    录屏
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=摄像头&amp;t=blog" target="_blank">
    摄像头
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=编码&amp;t=blog" target="_blank">
    编码
   </a>
  </div>
  <div class="tags-box">
   <span class="label">
    个人分类：
   </span>
   <a class="tag-link" href="https://blog.csdn.net/leixiaohua1020/article/category/1360795" target="_blank">
    FFMPEG
   </a>
  </div>
  <div class="tags-box">
   <span class="label">
    所属专栏：
   </span>
   <a class="tag-link" href="https://blog.csdn.net/column/details/ffmpeg-devel.html" target="_blank">
    FFmpeg
   </a>
  </div>
 </div>
 <!-- !empty($pre_next_article[0]) -->
</div>
<div class="recommend-box">
                            <div style="background: #fff; border: dashed 1px #666; padding-left: 1em; padding-top: 1em; padding-bottom: 1em;">
                                <span style="font-size: 0.8em; font-weight: bold;">
                                    此PDF由<a style="color:#0000ff" href="http://www.github.com/spygg"  target="_blank">spygg</a>生成,请尊重原作者版权!!!
                                    <br/>
                                    我的邮箱:liushidc@163.com
                                </span>
                                </div> 
                        </div>
                    </main>
      
                </div>

            <script>
                var recommendCount = 0;
                var articleTit = "";
                var articleId = "";
                var commentscount = 0;

                //1禁止评论，2正常
                var commentAuth = 1;
                //百度搜索
                var baiduKey = "";
                var needInsertBaidu = "";
            </script>
            <script src="https://csdnimg.cn/release/phoenix/template/js/detail-effe72036e.min.js"></script>
            </body>
        </html>