
            <!DOCTYPE html>
            <html lang="zh-CN">
                <head>
                    <meta charset="UTF-8">
                    <title>
 FFmpeg源代码简单分析：libswscale的sws_scale() - CSDN博客
</title>

                <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/detail-60a2c245da.min.css">
                <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/themes/skin3-template/skin3-template-88717cedf2.min.css">

                <script type="text/javascript">
                var username = "";
                </script>

                <script src="https://csdnimg.cn/public/common/libs/jquery/jquery-1.9.1.min.js" type="text/javascript"></script>

                <!-- 新版上报 -->
                <!-- 新版上报end -->
                <link rel="stylesheet" href="https://csdnimg.cn/public/sandalstrap/1.3/css/sandalstrap.min.css"> 
                </head>
                <body>    
        
                    <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/blog_code-c3a0c33d5c.css">
                    <div class="container clearfix pt0" id="mainBox">
        <main style="width: 100%;"><div class="blog-content-box">
 <div class="article-title-box" id="article_anchors_76">
  <span class="article-type type-1 float-left">
   原
  </span>
  <h1 class="title-article">
   FFmpeg源代码简单分析：libswscale的sws_scale()
  </h1>
 </div>
 <div class="article-info-box">
  <div class="article-bar-top d-flex">
   <span class="time">
    2015年03月17日 20:02:33
   </span>
   <div ">
    <span class="read-count">
     阅读数：25908
    </span>
   </div>
  </div>
 </div>
 <article>
  <div class="article_content clearfix csdn-tracking-statistics" data-dsm="post" data-mod="popu_307" data-pid="blog" id="article_content">
   <link href="https://csdnimg.cn/release/phoenix/template/css/htmledit_views-0a60691e80.css" rel="stylesheet"/>
   <div class="htmledit_views">
    <p>
    </p>
    <p align="left">
     =====================================================
    </p>
    <p align="left">
     FFmpeg的库函数源代码分析文章列表：
    </p>
    <p align="left">
     【架构图】
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44220151" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码结构图 -
      </span>
      <span style="color:blue;">
       解码
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44226355" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码结构图 -
      </span>
      <span style="color:blue;">
       编码
      </span>
     </a>
    </p>
    <p align="left">
     【通用】
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/12677129" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       av_register_all()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/12677265" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avcodec_register_all()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/41176777" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：内存的分配和释放（
      </span>
      <span style="color:blue;">
       av_malloc()
      </span>
      <span style="color:blue;">
       、
      </span>
      <span style="color:blue;">
       av_free()
      </span>
      <span style="color:blue;">
       等）
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/41181155" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：常见结构体的初始化和销毁（
      </span>
      <span style="color:blue;">
       AVFormatContext
      </span>
      <span style="color:blue;">
       ，
      </span>
      <span style="color:blue;">
       AVFrame
      </span>
      <span style="color:blue;">
       等）
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/41199947" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avio_open2()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44084557" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       av_find_decoder()
      </span>
      <span style="color:blue;">
       和
      </span>
      <span style="color:blue;">
       av_find_encoder()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44117891" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avcodec_open2()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44206699" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avcodec_close()
      </span>
     </a>
    </p>
    <p align="left">
     【解码】
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/8661601" target="_blank">
      <span style="color:blue;">
       图解
      </span>
      <span style="color:blue;">
       FFMPEG
      </span>
      <span style="color:blue;">
       打开媒体的函数
      </span>
      <span style="color:blue;">
       avformat_open_input
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44064715" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avformat_open_input()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44084321" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avformat_find_stream_info()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/12678577" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       av_read_frame()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/12679719" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avcodec_decode_video2()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44110683" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avformat_close_input()
      </span>
     </a>
    </p>
    <p align="left">
     【编码】
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/41198929" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avformat_alloc_output_context2()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44116215" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avformat_write_header()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44206485" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       avcodec_encode_video()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44199673" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       av_write_frame()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44201645" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       av_write_trailer()
      </span>
     </a>
    </p>
    <p align="left">
     【其它】
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44243155" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：日志输出系统（
      </span>
      <span style="color:blue;">
       av_log()
      </span>
      <span style="color:blue;">
       等）
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44268323" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：结构体成员管理系统
      </span>
      <span style="color:blue;">
       -AVClass
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44279329" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：结构体成员管理系统
      </span>
      <span style="color:blue;">
       -AVOption
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44305697" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       libswscale
      </span>
      <span style="color:blue;">
       的
      </span>
      <span style="color:blue;">
       sws_getContext()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44346687" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       libswscale
      </span>
      <span style="color:blue;">
       的
      </span>
      <span style="color:blue;">
       sws_scale()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/41211121" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       libavdevice
      </span>
      <span style="color:blue;">
       的
      </span>
      <span style="color:blue;">
       avdevice_register_all()
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44597955" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       libavdevice
      </span>
      <span style="color:blue;">
       的
      </span>
      <span style="color:blue;">
       gdigrab
      </span>
     </a>
    </p>
    <p align="left">
     【脚本】
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44556525" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       makefile
      </span>
     </a>
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44587465" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       源代码简单分析：
      </span>
      <span style="color:blue;">
       configure
      </span>
     </a>
    </p>
    <p align="left">
     【H.264】
    </p>
    <p align="left">
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44864509" target="_blank">
      <span style="color:blue;">
       FFmpeg
      </span>
      <span style="color:blue;">
       的
      </span>
      <span style="color:blue;">
       H.264
      </span>
      <span style="color:blue;">
       解码器源代码简单分析：概述
      </span>
     </a>
    </p>
    <p align="left">
     =====================================================
    </p>
    <br/>
    <p>
     本文继续上一篇文章《
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/44305697" target="_blank">
      FFmpeg源代码分析：sws_getContext()
     </a>
     》的内容，简单分析FFmpeg的图像处理（缩放，YUV/RGB格式转换）类库libswsscale中的sws_scale()函数。libswscale是一个主要用于处理图片像素数据的类库。可以完成图片像素格式的转换，图片的拉伸等工作。有关libswscale的使用可以参考文章：
     <br/>
     《
     <a href="http://blog.csdn.net/leixiaohua1020/article/details/42134965" target="_blank">
      最简单的基于FFmpeg的libswscale的示例（YUV转RGB）
     </a>
     》
    </p>
    <p>
     该类库常用的函数数量很少，一般情况下就3个：
     <br/>
    </p>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <p>
      sws_getContext()：初始化一个SwsContext。
     </p>
     <p>
      sws_scale()：处理图像数据。
     </p>
     <p>
      sws_freeContext()：释放一个SwsContext。
     </p>
    </blockquote>
    <p>
     在分析sws_scale()的源代码之前，先简单回顾一下上篇文章中分析得到的两张图。
    </p>
    <p>
     <br/>
    </p>
    <h2>
     函数调用结构图
    </h2>
    <p>
    </p>
    <p>
     分析得到的libswscale的函数调用关系如下图所示。
    </p>
    <p>
    </p>
    <div style="text-align: center;">
     <img alt="" src="http://img.blog.csdn.net/20150317194655486"/>
     <br/>
    </div>
    <h2>
     Libswscale处理数据流程
    </h2>
    <p>
    </p>
    <p>
     Libswscale处理像素数据的流程可以概括为下图。
    </p>
    <p>
    </p>
    <div style="text-align: center;">
     <img alt="" src="http://img.blog.csdn.net/20150317194542751"/>
     <br/>
    </div>
    从图中可以看出，libswscale处理数据有两条最主要的方式：unscaled和scaled。unscaled用于处理不需要拉伸的像素数据（属于比较特殊的情况），scaled用于处理需要拉伸的像素数据。Unscaled只需要对图像像素格式进行转换；而Scaled则除了对像素格式进行转换之外，还需要对图像进行缩放。Scaled方式可以分成以下几个步骤：
    <br/>
    <p>
    </p>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <p>
      XXX to YUV Converter：首相将数据像素数据转换为8bitYUV格式；
     </p>
     <p>
      Horizontal scaler：水平拉伸图像，并且转换为15bitYUV；
     </p>
     <p>
      Vertical scaler：垂直拉伸图像；
     </p>
     <p>
      Output converter：转换为输出像素格式。
     </p>
    </blockquote>
    <p>
     <br/>
    </p>
    <h2>
     sws_scale()
    </h2>
    <p>
    </p>
    <p>
     sws_scale()是用于转换像素的函数。它的声明位于libswscale\swscale.h，如下所示。
     <br/>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_1_9591301">/**
 * Scale the image slice in srcSlice and put the resulting scaled
 * slice in the image in dst. A slice is a sequence of consecutive
 * rows in an image.
 *
 * Slices have to be provided in sequential order, either in
 * top-bottom or bottom-top order. If slices are provided in
 * non-sequential order the behavior of the function is undefined.
 *
 * @param c         the scaling context previously created with
 *                  sws_getContext()
 * @param srcSlice  the array containing the pointers to the planes of
 *                  the source slice
 * @param srcStride the array containing the strides for each plane of
 *                  the source image
 * @param srcSliceY the position in the source image of the slice to
 *                  process, that is the number (counted starting from
 *                  zero) in the image of the first row of the slice
 * @param srcSliceH the height of the source slice, that is the number
 *                  of rows in the slice
 * @param dst       the array containing the pointers to the planes of
 *                  the destination image
 * @param dstStride the array containing the strides for each plane of
 *                  the destination image
 * @return          the height of the output slice
 */
int sws_scale(struct SwsContext *c, const uint8_t *const srcSlice[],
              const int srcStride[], int srcSliceY, int srcSliceH,
              uint8_t *const dst[], const int dstStride[]);</pre>
    <br/>
    sws_scale()的定义位于libswscale\swscale.c，如下所示。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_2_8605637">/**
 * swscale wrapper, so we don't need to export the SwsContext.
 * Assumes planar YUV to be in YUV order instead of YVU.
 */
int sws_scale(struct SwsContext *c,
                                  const uint8_t * const srcSlice[],
                                  const int srcStride[], int srcSliceY,
                                  int srcSliceH, uint8_t *const dst[],
                                  const int dstStride[])
{
    int i, ret;
    const uint8_t *src2[4];
    uint8_t *dst2[4];
    uint8_t *rgb0_tmp = NULL;
    //检查输入参数
    if (!srcStride || !dstStride || !dst || !srcSlice) {
        av_log(c, AV_LOG_ERROR, "One of the input parameters to sws_scale() is NULL, please check the calling code\n");
        return 0;
    }
    if (c-&gt;cascaded_context[0] &amp;&amp; srcSliceY == 0 &amp;&amp; srcSliceH == c-&gt;cascaded_context[0]-&gt;srcH) {
        ret = sws_scale(c-&gt;cascaded_context[0],
                        srcSlice, srcStride, srcSliceY, srcSliceH,
                        c-&gt;cascaded_tmp, c-&gt;cascaded_tmpStride);
        if (ret &lt; 0)
            return ret;
        ret = sws_scale(c-&gt;cascaded_context[1],
                        (const uint8_t * const * )c-&gt;cascaded_tmp, c-&gt;cascaded_tmpStride, 0, c-&gt;cascaded_context[0]-&gt;dstH,
                        dst, dstStride);
        return ret;
    }

    memcpy(src2, srcSlice, sizeof(src2));
    memcpy(dst2, dst, sizeof(dst2));

    // do not mess up sliceDir if we have a "trailing" 0-size slice
    if (srcSliceH == 0)
        return 0;
    //检查
    if (!check_image_pointers(srcSlice, c-&gt;srcFormat, srcStride)) {
        av_log(c, AV_LOG_ERROR, "bad src image pointers\n");
        return 0;
    }
    if (!check_image_pointers((const uint8_t* const*)dst, c-&gt;dstFormat, dstStride)) {
        av_log(c, AV_LOG_ERROR, "bad dst image pointers\n");
        return 0;
    }

    if (c-&gt;sliceDir == 0 &amp;&amp; srcSliceY != 0 &amp;&amp; srcSliceY + srcSliceH != c-&gt;srcH) {
        av_log(c, AV_LOG_ERROR, "Slices start in the middle!\n");
        return 0;
    }
    if (c-&gt;sliceDir == 0) {
        if (srcSliceY == 0) c-&gt;sliceDir = 1; else c-&gt;sliceDir = -1;
    }
    //使用调色板palette的特殊处理？应该不常见
    if (usePal(c-&gt;srcFormat)) {
        for (i = 0; i &lt; 256; i++) {
            int r, g, b, y, u, v, a = 0xff;
            if (c-&gt;srcFormat == AV_PIX_FMT_PAL8) {
                uint32_t p = ((const uint32_t *)(srcSlice[1]))[i];
                a = (p &gt;&gt; 24) &amp; 0xFF;
                r = (p &gt;&gt; 16) &amp; 0xFF;
                g = (p &gt;&gt;  8) &amp; 0xFF;
                b =  p        &amp; 0xFF;
            } else if (c-&gt;srcFormat == AV_PIX_FMT_RGB8) {
                r = ( i &gt;&gt; 5     ) * 36;
                g = ((i &gt;&gt; 2) &amp; 7) * 36;
                b = ( i       &amp; 3) * 85;
            } else if (c-&gt;srcFormat == AV_PIX_FMT_BGR8) {
                b = ( i &gt;&gt; 6     ) * 85;
                g = ((i &gt;&gt; 3) &amp; 7) * 36;
                r = ( i       &amp; 7) * 36;
            } else if (c-&gt;srcFormat == AV_PIX_FMT_RGB4_BYTE) {
                r = ( i &gt;&gt; 3     ) * 255;
                g = ((i &gt;&gt; 1) &amp; 3) * 85;
                b = ( i       &amp; 1) * 255;
            } else if (c-&gt;srcFormat == AV_PIX_FMT_GRAY8 || c-&gt;srcFormat == AV_PIX_FMT_GRAY8A) {
                r = g = b = i;
            } else {
                av_assert1(c-&gt;srcFormat == AV_PIX_FMT_BGR4_BYTE);
                b = ( i &gt;&gt; 3     ) * 255;
                g = ((i &gt;&gt; 1) &amp; 3) * 85;
                r = ( i       &amp; 1) * 255;
            }
#define RGB2YUV_SHIFT 15
#define BY ( (int) (0.114 * 219 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define BV (-(int) (0.081 * 224 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define BU ( (int) (0.500 * 224 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define GY ( (int) (0.587 * 219 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define GV (-(int) (0.419 * 224 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define GU (-(int) (0.331 * 224 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define RY ( (int) (0.299 * 219 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define RV ( (int) (0.500 * 224 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))
#define RU (-(int) (0.169 * 224 / 255 * (1 &lt;&lt; RGB2YUV_SHIFT) + 0.5))

            y = av_clip_uint8((RY * r + GY * g + BY * b + ( 33 &lt;&lt; (RGB2YUV_SHIFT - 1))) &gt;&gt; RGB2YUV_SHIFT);
            u = av_clip_uint8((RU * r + GU * g + BU * b + (257 &lt;&lt; (RGB2YUV_SHIFT - 1))) &gt;&gt; RGB2YUV_SHIFT);
            v = av_clip_uint8((RV * r + GV * g + BV * b + (257 &lt;&lt; (RGB2YUV_SHIFT - 1))) &gt;&gt; RGB2YUV_SHIFT);
            c-&gt;pal_yuv[i]= y + (u&lt;&lt;8) + (v&lt;&lt;16) + ((unsigned)a&lt;&lt;24);

            switch (c-&gt;dstFormat) {
            case AV_PIX_FMT_BGR32:
#if !HAVE_BIGENDIAN
            case AV_PIX_FMT_RGB24:
#endif
                c-&gt;pal_rgb[i]=  r + (g&lt;&lt;8) + (b&lt;&lt;16) + ((unsigned)a&lt;&lt;24);
                break;
            case AV_PIX_FMT_BGR32_1:
#if HAVE_BIGENDIAN
            case AV_PIX_FMT_BGR24:
#endif
                c-&gt;pal_rgb[i]= a + (r&lt;&lt;8) + (g&lt;&lt;16) + ((unsigned)b&lt;&lt;24);
                break;
            case AV_PIX_FMT_RGB32_1:
#if HAVE_BIGENDIAN
            case AV_PIX_FMT_RGB24:
#endif
                c-&gt;pal_rgb[i]= a + (b&lt;&lt;8) + (g&lt;&lt;16) + ((unsigned)r&lt;&lt;24);
                break;
            case AV_PIX_FMT_RGB32:
#if !HAVE_BIGENDIAN
            case AV_PIX_FMT_BGR24:
#endif
            default:
                c-&gt;pal_rgb[i]=  b + (g&lt;&lt;8) + (r&lt;&lt;16) + ((unsigned)a&lt;&lt;24);
            }
        }
    }
    //Alpha的特殊处理?
    if (c-&gt;src0Alpha &amp;&amp; !c-&gt;dst0Alpha &amp;&amp; isALPHA(c-&gt;dstFormat)) {
        uint8_t *base;
        int x,y;
        rgb0_tmp = av_malloc(FFABS(srcStride[0]) * srcSliceH + 32);
        if (!rgb0_tmp)
            return AVERROR(ENOMEM);

        base = srcStride[0] &lt; 0 ? rgb0_tmp - srcStride[0] * (srcSliceH-1) : rgb0_tmp;
        for (y=0; y&lt;srcSliceH; y++){
            memcpy(base + srcStride[0]*y, src2[0] + srcStride[0]*y, 4*c-&gt;srcW);
            for (x=c-&gt;src0Alpha-1; x&lt;4*c-&gt;srcW; x+=4) {
                base[ srcStride[0]*y + x] = 0xFF;
            }
        }
        src2[0] = base;
    }
    //XYZ的特殊处理?
    if (c-&gt;srcXYZ &amp;&amp; !(c-&gt;dstXYZ &amp;&amp; c-&gt;srcW==c-&gt;dstW &amp;&amp; c-&gt;srcH==c-&gt;dstH)) {
        uint8_t *base;
        rgb0_tmp = av_malloc(FFABS(srcStride[0]) * srcSliceH + 32);
        if (!rgb0_tmp)
            return AVERROR(ENOMEM);

        base = srcStride[0] &lt; 0 ? rgb0_tmp - srcStride[0] * (srcSliceH-1) : rgb0_tmp;

        xyz12Torgb48(c, (uint16_t*)base, (const uint16_t*)src2[0], srcStride[0]/2, srcSliceH);
        src2[0] = base;
    }

    if (!srcSliceY &amp;&amp; (c-&gt;flags &amp; SWS_BITEXACT) &amp;&amp; c-&gt;dither == SWS_DITHER_ED &amp;&amp; c-&gt;dither_error[0])
        for (i = 0; i &lt; 4; i++)
            memset(c-&gt;dither_error[i], 0, sizeof(c-&gt;dither_error[0][0]) * (c-&gt;dstW+2));


    // copy strides, so they can safely be modified
    // sliceDir: 1 = top-to-bottom; -1 = bottom-to-top;
    if (c-&gt;sliceDir == 1) {
        // slices go from top to bottom
        int srcStride2[4] = { srcStride[0], srcStride[1], srcStride[2],
                              srcStride[3] };
        int dstStride2[4] = { dstStride[0], dstStride[1], dstStride[2],
                              dstStride[3] };

        reset_ptr(src2, c-&gt;srcFormat);
        reset_ptr((void*)dst2, c-&gt;dstFormat);

        /* reset slice direction at end of frame */
        if (srcSliceY + srcSliceH == c-&gt;srcH)
            c-&gt;sliceDir = 0;
        //关键：调用
        ret = c-&gt;swscale(c, src2, srcStride2, srcSliceY, srcSliceH, dst2,
                          dstStride2);
    } else {
        // slices go from bottom to top =&gt; we flip the image internally
        int srcStride2[4] = { -srcStride[0], -srcStride[1], -srcStride[2],
                              -srcStride[3] };
        int dstStride2[4] = { -dstStride[0], -dstStride[1], -dstStride[2],
                              -dstStride[3] };

        src2[0] += (srcSliceH - 1) * srcStride[0];
        if (!usePal(c-&gt;srcFormat))
            src2[1] += ((srcSliceH &gt;&gt; c-&gt;chrSrcVSubSample) - 1) * srcStride[1];
        src2[2] += ((srcSliceH &gt;&gt; c-&gt;chrSrcVSubSample) - 1) * srcStride[2];
        src2[3] += (srcSliceH - 1) * srcStride[3];
        dst2[0] += ( c-&gt;dstH                         - 1) * dstStride[0];
        dst2[1] += ((c-&gt;dstH &gt;&gt; c-&gt;chrDstVSubSample) - 1) * dstStride[1];
        dst2[2] += ((c-&gt;dstH &gt;&gt; c-&gt;chrDstVSubSample) - 1) * dstStride[2];
        dst2[3] += ( c-&gt;dstH                         - 1) * dstStride[3];

        reset_ptr(src2, c-&gt;srcFormat);
        reset_ptr((void*)dst2, c-&gt;dstFormat);

        /* reset slice direction at end of frame */
        if (!srcSliceY)
            c-&gt;sliceDir = 0;
        //关键：调用
        ret = c-&gt;swscale(c, src2, srcStride2, c-&gt;srcH-srcSliceY-srcSliceH,
                          srcSliceH, dst2, dstStride2);
    }


    if (c-&gt;dstXYZ &amp;&amp; !(c-&gt;srcXYZ &amp;&amp; c-&gt;srcW==c-&gt;dstW &amp;&amp; c-&gt;srcH==c-&gt;dstH)) {
        /* replace on the same data */
        rgb48Toxyz12(c, (uint16_t*)dst2[0], (const uint16_t*)dst2[0], dstStride[0]/2, ret);
    }

    av_free(rgb0_tmp);
    return ret;
}
</pre>
    <br/>
    从sws_scale()的定义可以看出，它封装了SwsContext中的swscale()（注意这个函数中间没有“_”）。函数最重要的一句代码就是“c-&gt;swscale()”。除此之外，函数还做了一些增加“兼容性”的一些处理。函数的主要步骤如下所示。
    <p>
    </p>
    <p>
     <strong>
      1.检查输入的图像参数的合理性。
     </strong>
    </p>
    <p>
     这一步骤首先检查输入输出的参数是否为空，然后通过调用check_image_pointers()检查输入输出图像的内存是否正确分配。check_image_pointers()的定义如下所示。
     <br/>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_3_8798827">static int check_image_pointers(const uint8_t * const data[4], enum AVPixelFormat pix_fmt,
                                const int linesizes[4])
{
    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pix_fmt);
    int i;

    for (i = 0; i &lt; 4; i++) {
        int plane = desc-&gt;comp[i].plane;
        if (!data[plane] || !linesizes[plane])
            return 0;
    }

    return 1;
}
</pre>
    <br/>
    从check_image_pointers()的定义可以看出，在特定像素格式前提下，如果该像素格式应该包含像素的分量为空，就返回0，否则返回1。
    <br/>
    <strong>
     2.如果输入像素数据中使用了“调色板”（palette），则进行一些相应的处理。这一步通过函数usePal()来判定。
    </strong>
    usePal()的定义如下。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_4_3485140">static av_always_inline int usePal(enum AVPixelFormat pix_fmt)
{
    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pix_fmt);
    av_assert0(desc);
    return (desc-&gt;flags &amp; AV_PIX_FMT_FLAG_PAL) || (desc-&gt;flags &amp; AV_PIX_FMT_FLAG_PSEUDOPAL);
}</pre>
    <br/>
    从定义可以看出该函数通过判定AVPixFmtDescriptor中的flag是否包含AV_PIX_FMT_FLAG_PAL来断定像素格式是否使用了“调色板”。
    <br/>
    <strong>
     3.其它一些特殊格式的处理，比如说Alpha，XYZ等的处理（这方面没有研究过）。
     <br/>
     4.如果输入的图像的扫描方式是从底部到顶部的（一般情况下是从顶部到底部），则将图像进行反转。
     <br/>
     5.调用SwsContext中的swscale()。
    </strong>
    <p>
    </p>
    <p>
     <br/>
    </p>
    <h2>
     SwsContext中的swscale()
    </h2>
    <p>
    </p>
    <p>
     swscale这个变量的类型是SwsFunc，实际上就是一个函数指针。它是整个类库的
     <span style="color:#ff0000;">
      <strong>
       核心
      </strong>
     </span>
     。当我们从外部调用swscale()函数的时候，实际上就是调用了SwsContext中的这个名称为swscale的变量（注意外部函数接口和这个内部函数指针的名字是一样的，但不是一回事）。
     <br/>
     可以看一下SwsFunc这个类型的定义：
     <br/>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_5_6742993">typedef int (*SwsFunc)(struct SwsContext *context, const uint8_t *src[],
                       int srcStride[], int srcSliceY, int srcSliceH,
                       uint8_t *dst[], int dstStride[]);</pre>
    可以看出SwsFunc的定义的参数类型和libswscale类库外部接口函数swscale()的参数类型一模一样。
    <br/>
    在libswscale中，该指针的指向可以分成2种情况：
    <br/>
    <p>
    </p>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <p>
      1.图像没有伸缩的时候，指向专有的像素转换函数
     </p>
     <p>
      2.图像有伸缩的时候，指向swscale()函数。
     </p>
    </blockquote>
    <p>
     在调用sws_getContext()初始化SwsContext的时候，会在其子函数sws_init_context()中对swscale指针进行赋值。如果图像没有进行拉伸，则会调用ff_get_unscaled_swscale()对其进行赋值；如果图像进行了拉伸，则会调用ff_getSwsFunc()对其进行赋值。下面分别看一下这2种情况。
    </p>
    <p>
     <br/>
    </p>
    <h2>
     没有拉伸--专有的像素转换函数
    </h2>
    <p>
    </p>
    <p>
     如果图像没有进行拉伸，则会调用ff_get_unscaled_swscale()对SwsContext的swscale进行赋值。上篇文章中记录了这个函数，在这里回顾一下。
    </p>
    <p>
    </p>
    <h2>
     ff_get_unscaled_swscale()
    </h2>
    ff_get_unscaled_swscale()的定义如下。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_6_2268338">void ff_get_unscaled_swscale(SwsContext *c)
{
    const enum AVPixelFormat srcFormat = c-&gt;srcFormat;
    const enum AVPixelFormat dstFormat = c-&gt;dstFormat;
    const int flags = c-&gt;flags;
    const int dstH = c-&gt;dstH;
    int needsDither;

    needsDither = isAnyRGB(dstFormat) &amp;&amp;
            c-&gt;dstFormatBpp &lt; 24 &amp;&amp;
           (c-&gt;dstFormatBpp &lt; c-&gt;srcFormatBpp || (!isAnyRGB(srcFormat)));

    /* yv12_to_nv12 */
    if ((srcFormat == AV_PIX_FMT_YUV420P || srcFormat == AV_PIX_FMT_YUVA420P) &amp;&amp;
        (dstFormat == AV_PIX_FMT_NV12 || dstFormat == AV_PIX_FMT_NV21)) {
        c-&gt;swscale = planarToNv12Wrapper;
    }
    /* nv12_to_yv12 */
    if (dstFormat == AV_PIX_FMT_YUV420P &amp;&amp;
        (srcFormat == AV_PIX_FMT_NV12 || srcFormat == AV_PIX_FMT_NV21)) {
        c-&gt;swscale = nv12ToPlanarWrapper;
    }
    /* yuv2bgr */
    if ((srcFormat == AV_PIX_FMT_YUV420P || srcFormat == AV_PIX_FMT_YUV422P ||
         srcFormat == AV_PIX_FMT_YUVA420P) &amp;&amp; isAnyRGB(dstFormat) &amp;&amp;
        !(flags &amp; SWS_ACCURATE_RND) &amp;&amp; (c-&gt;dither == SWS_DITHER_BAYER || c-&gt;dither == SWS_DITHER_AUTO) &amp;&amp; !(dstH &amp; 1)) {
        c-&gt;swscale = ff_yuv2rgb_get_func_ptr(c);
    }

    if (srcFormat == AV_PIX_FMT_YUV410P &amp;&amp; !(dstH &amp; 3) &amp;&amp;
        (dstFormat == AV_PIX_FMT_YUV420P || dstFormat == AV_PIX_FMT_YUVA420P) &amp;&amp;
        !(flags &amp; SWS_BITEXACT)) {
        c-&gt;swscale = yvu9ToYv12Wrapper;
    }

    /* bgr24toYV12 */
    if (srcFormat == AV_PIX_FMT_BGR24 &amp;&amp;
        (dstFormat == AV_PIX_FMT_YUV420P || dstFormat == AV_PIX_FMT_YUVA420P) &amp;&amp;
        !(flags &amp; SWS_ACCURATE_RND))
        c-&gt;swscale = bgr24ToYv12Wrapper;

    /* RGB/BGR -&gt; RGB/BGR (no dither needed forms) */
    if (isAnyRGB(srcFormat) &amp;&amp; isAnyRGB(dstFormat) &amp;&amp; findRgbConvFn(c)
        &amp;&amp; (!needsDither || (c-&gt;flags&amp;(SWS_FAST_BILINEAR|SWS_POINT))))
        c-&gt;swscale = rgbToRgbWrapper;

    if ((srcFormat == AV_PIX_FMT_GBRP &amp;&amp; dstFormat == AV_PIX_FMT_GBRAP) ||
        (srcFormat == AV_PIX_FMT_GBRAP &amp;&amp; dstFormat == AV_PIX_FMT_GBRP))
        c-&gt;swscale = planarRgbToplanarRgbWrapper;

#define isByteRGB(f) (             \
        f == AV_PIX_FMT_RGB32   || \
        f == AV_PIX_FMT_RGB32_1 || \
        f == AV_PIX_FMT_RGB24   || \
        f == AV_PIX_FMT_BGR32   || \
        f == AV_PIX_FMT_BGR32_1 || \
        f == AV_PIX_FMT_BGR24)

    if (srcFormat == AV_PIX_FMT_GBRP &amp;&amp; isPlanar(srcFormat) &amp;&amp; isByteRGB(dstFormat))
        c-&gt;swscale = planarRgbToRgbWrapper;

    if ((srcFormat == AV_PIX_FMT_RGB48LE  || srcFormat == AV_PIX_FMT_RGB48BE  ||
         srcFormat == AV_PIX_FMT_BGR48LE  || srcFormat == AV_PIX_FMT_BGR48BE  ||
         srcFormat == AV_PIX_FMT_RGBA64LE || srcFormat == AV_PIX_FMT_RGBA64BE ||
         srcFormat == AV_PIX_FMT_BGRA64LE || srcFormat == AV_PIX_FMT_BGRA64BE) &amp;&amp;
        (dstFormat == AV_PIX_FMT_GBRP9LE  || dstFormat == AV_PIX_FMT_GBRP9BE  ||
         dstFormat == AV_PIX_FMT_GBRP10LE || dstFormat == AV_PIX_FMT_GBRP10BE ||
         dstFormat == AV_PIX_FMT_GBRP12LE || dstFormat == AV_PIX_FMT_GBRP12BE ||
         dstFormat == AV_PIX_FMT_GBRP14LE || dstFormat == AV_PIX_FMT_GBRP14BE ||
         dstFormat == AV_PIX_FMT_GBRP16LE || dstFormat == AV_PIX_FMT_GBRP16BE ||
         dstFormat == AV_PIX_FMT_GBRAP16LE || dstFormat == AV_PIX_FMT_GBRAP16BE ))
        c-&gt;swscale = Rgb16ToPlanarRgb16Wrapper;

    if ((srcFormat == AV_PIX_FMT_GBRP9LE  || srcFormat == AV_PIX_FMT_GBRP9BE  ||
         srcFormat == AV_PIX_FMT_GBRP16LE || srcFormat == AV_PIX_FMT_GBRP16BE ||
         srcFormat == AV_PIX_FMT_GBRP10LE || srcFormat == AV_PIX_FMT_GBRP10BE ||
         srcFormat == AV_PIX_FMT_GBRP12LE || srcFormat == AV_PIX_FMT_GBRP12BE ||
         srcFormat == AV_PIX_FMT_GBRP14LE || srcFormat == AV_PIX_FMT_GBRP14BE ||
         srcFormat == AV_PIX_FMT_GBRAP16LE || srcFormat == AV_PIX_FMT_GBRAP16BE) &amp;&amp;
        (dstFormat == AV_PIX_FMT_RGB48LE  || dstFormat == AV_PIX_FMT_RGB48BE  ||
         dstFormat == AV_PIX_FMT_BGR48LE  || dstFormat == AV_PIX_FMT_BGR48BE  ||
         dstFormat == AV_PIX_FMT_RGBA64LE || dstFormat == AV_PIX_FMT_RGBA64BE ||
         dstFormat == AV_PIX_FMT_BGRA64LE || dstFormat == AV_PIX_FMT_BGRA64BE))
        c-&gt;swscale = planarRgb16ToRgb16Wrapper;

    if (av_pix_fmt_desc_get(srcFormat)-&gt;comp[0].depth_minus1 == 7 &amp;&amp;
        isPackedRGB(srcFormat) &amp;&amp; dstFormat == AV_PIX_FMT_GBRP)
        c-&gt;swscale = rgbToPlanarRgbWrapper;

    if (isBayer(srcFormat)) {
        if (dstFormat == AV_PIX_FMT_RGB24)
            c-&gt;swscale = bayer_to_rgb24_wrapper;
        else if (dstFormat == AV_PIX_FMT_YUV420P)
            c-&gt;swscale = bayer_to_yv12_wrapper;
        else if (!isBayer(dstFormat)) {
            av_log(c, AV_LOG_ERROR, "unsupported bayer conversion\n");
            av_assert0(0);
        }
    }

    /* bswap 16 bits per pixel/component packed formats */
    if (IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BAYER_BGGR16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BAYER_RGGB16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BAYER_GBRG16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BAYER_GRBG16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BGR444) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BGR48)  ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BGRA64) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BGR555) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BGR565) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_BGRA64) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_GRAY16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YA16)   ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_GBRP9)  ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_GBRP10) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_GBRP12) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_GBRP14) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_GBRP16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_GBRAP16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_RGB444) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_RGB48)  ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_RGBA64) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_RGB555) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_RGB565) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_RGBA64) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_XYZ12)  ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV420P9)  ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV420P10) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV420P12) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV420P14) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV420P16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV422P9)  ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV422P10) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV422P12) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV422P14) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV422P16) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV444P9)  ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV444P10) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV444P12) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV444P14) ||
        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, AV_PIX_FMT_YUV444P16))
        c-&gt;swscale = packed_16bpc_bswap;

    if (usePal(srcFormat) &amp;&amp; isByteRGB(dstFormat))
        c-&gt;swscale = palToRgbWrapper;

    if (srcFormat == AV_PIX_FMT_YUV422P) {
        if (dstFormat == AV_PIX_FMT_YUYV422)
            c-&gt;swscale = yuv422pToYuy2Wrapper;
        else if (dstFormat == AV_PIX_FMT_UYVY422)
            c-&gt;swscale = yuv422pToUyvyWrapper;
    }

    /* LQ converters if -sws 0 or -sws 4*/
    if (c-&gt;flags&amp;(SWS_FAST_BILINEAR|SWS_POINT)) {
        /* yv12_to_yuy2 */
        if (srcFormat == AV_PIX_FMT_YUV420P || srcFormat == AV_PIX_FMT_YUVA420P) {
            if (dstFormat == AV_PIX_FMT_YUYV422)
                c-&gt;swscale = planarToYuy2Wrapper;
            else if (dstFormat == AV_PIX_FMT_UYVY422)
                c-&gt;swscale = planarToUyvyWrapper;
        }
    }
    if (srcFormat == AV_PIX_FMT_YUYV422 &amp;&amp;
       (dstFormat == AV_PIX_FMT_YUV420P || dstFormat == AV_PIX_FMT_YUVA420P))
        c-&gt;swscale = yuyvToYuv420Wrapper;
    if (srcFormat == AV_PIX_FMT_UYVY422 &amp;&amp;
       (dstFormat == AV_PIX_FMT_YUV420P || dstFormat == AV_PIX_FMT_YUVA420P))
        c-&gt;swscale = uyvyToYuv420Wrapper;
    if (srcFormat == AV_PIX_FMT_YUYV422 &amp;&amp; dstFormat == AV_PIX_FMT_YUV422P)
        c-&gt;swscale = yuyvToYuv422Wrapper;
    if (srcFormat == AV_PIX_FMT_UYVY422 &amp;&amp; dstFormat == AV_PIX_FMT_YUV422P)
        c-&gt;swscale = uyvyToYuv422Wrapper;

#define isPlanarGray(x) (isGray(x) &amp;&amp; (x) != AV_PIX_FMT_YA8 &amp;&amp; (x) != AV_PIX_FMT_YA16LE &amp;&amp; (x) != AV_PIX_FMT_YA16BE)
    /* simple copy */
    if ( srcFormat == dstFormat ||
        (srcFormat == AV_PIX_FMT_YUVA420P &amp;&amp; dstFormat == AV_PIX_FMT_YUV420P) ||
        (srcFormat == AV_PIX_FMT_YUV420P &amp;&amp; dstFormat == AV_PIX_FMT_YUVA420P) ||
        (isPlanarYUV(srcFormat) &amp;&amp; isPlanarGray(dstFormat)) ||
        (isPlanarYUV(dstFormat) &amp;&amp; isPlanarGray(srcFormat)) ||
        (isPlanarGray(dstFormat) &amp;&amp; isPlanarGray(srcFormat)) ||
        (isPlanarYUV(srcFormat) &amp;&amp; isPlanarYUV(dstFormat) &amp;&amp;
         c-&gt;chrDstHSubSample == c-&gt;chrSrcHSubSample &amp;&amp;
         c-&gt;chrDstVSubSample == c-&gt;chrSrcVSubSample &amp;&amp;
         dstFormat != AV_PIX_FMT_NV12 &amp;&amp; dstFormat != AV_PIX_FMT_NV21 &amp;&amp;
         srcFormat != AV_PIX_FMT_NV12 &amp;&amp; srcFormat != AV_PIX_FMT_NV21))
    {
        if (isPacked(c-&gt;srcFormat))
            c-&gt;swscale = packedCopyWrapper;
        else /* Planar YUV or gray */
            c-&gt;swscale = planarCopyWrapper;
    }

    if (ARCH_PPC)
        ff_get_unscaled_swscale_ppc(c);
//     if (ARCH_ARM)
//         ff_get_unscaled_swscale_arm(c);
}
</pre>
    <br/>
    从代码中可以看出，它根据输入输出像素格式的不同，选择了不同的转换函数。例如YUV420P转换NV12的时候，就会将planarToNv12Wrapper()赋值给SwsContext的swscale指针。
    <br/>
    <br/>
    <h2>
     有拉伸--swscale()
    </h2>
    <p>
    </p>
    <p>
     如果图像进行了拉伸，则会调用ff_getSwsFunc()对SwsContext的swscale进行赋值。上篇文章中记录了这个函数，在这里回顾一下。
     <br/>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_7_9986293">SwsFunc ff_getSwsFunc(SwsContext *c)
{
    sws_init_swscale(c);

    if (ARCH_PPC)
        ff_sws_init_swscale_ppc(c);
    if (ARCH_X86)
        ff_sws_init_swscale_x86(c);

    return swscale;
}
</pre>
    <br/>
    注意，sws_init_context()对SwsContext的swscale进行赋值的语句是：
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_8_9132708">c-&gt;swscale = ff_getSwsFunc(c);</pre>
    即把ff_getSwsFunc()的返回值赋值给SwsContext的swscale指针；而ff_getSwsFunc()的返回值是一个静态函数，名称就叫做“swscale”。
    <br/>
    下面我们看一下这个swscale()静态函数的定义。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_9_5422204">static int swscale(SwsContext *c, const uint8_t *src[],
                   int srcStride[], int srcSliceY,
                   int srcSliceH, uint8_t *dst[], int dstStride[])
{
    /* load a few things into local vars to make the code more readable?
     * and faster */
	//注意一下这些参数
	//以亮度为准
    const int srcW                   = c-&gt;srcW;
    const int dstW                   = c-&gt;dstW;
    const int dstH                   = c-&gt;dstH;
    //以色度为准
    const int chrDstW                = c-&gt;chrDstW;
    const int chrSrcW                = c-&gt;chrSrcW;
    const int lumXInc                = c-&gt;lumXInc;
    const int chrXInc                = c-&gt;chrXInc;
    const enum AVPixelFormat dstFormat = c-&gt;dstFormat;
    const int flags                  = c-&gt;flags;
    int32_t *vLumFilterPos           = c-&gt;vLumFilterPos;
    int32_t *vChrFilterPos           = c-&gt;vChrFilterPos;
    int32_t *hLumFilterPos           = c-&gt;hLumFilterPos;
    int32_t *hChrFilterPos           = c-&gt;hChrFilterPos;
    int16_t *hLumFilter              = c-&gt;hLumFilter;
    int16_t *hChrFilter              = c-&gt;hChrFilter;
    int32_t *lumMmxFilter            = c-&gt;lumMmxFilter;
    int32_t *chrMmxFilter            = c-&gt;chrMmxFilter;
    const int vLumFilterSize         = c-&gt;vLumFilterSize;
    const int vChrFilterSize         = c-&gt;vChrFilterSize;
    const int hLumFilterSize         = c-&gt;hLumFilterSize;
    const int hChrFilterSize         = c-&gt;hChrFilterSize;
    int16_t **lumPixBuf              = c-&gt;lumPixBuf;
    int16_t **chrUPixBuf             = c-&gt;chrUPixBuf;
    int16_t **chrVPixBuf             = c-&gt;chrVPixBuf;
    int16_t **alpPixBuf              = c-&gt;alpPixBuf;
    const int vLumBufSize            = c-&gt;vLumBufSize;
    const int vChrBufSize            = c-&gt;vChrBufSize;
    uint8_t *formatConvBuffer        = c-&gt;formatConvBuffer;
    uint32_t *pal                    = c-&gt;pal_yuv;
    yuv2planar1_fn yuv2plane1        = c-&gt;yuv2plane1;
    yuv2planarX_fn yuv2planeX        = c-&gt;yuv2planeX;
    yuv2interleavedX_fn yuv2nv12cX   = c-&gt;yuv2nv12cX;
    yuv2packed1_fn yuv2packed1       = c-&gt;yuv2packed1;
    yuv2packed2_fn yuv2packed2       = c-&gt;yuv2packed2;
    yuv2packedX_fn yuv2packedX       = c-&gt;yuv2packedX;
    yuv2anyX_fn yuv2anyX             = c-&gt;yuv2anyX;
    const int chrSrcSliceY           =                srcSliceY &gt;&gt; c-&gt;chrSrcVSubSample;
    const int chrSrcSliceH           = FF_CEIL_RSHIFT(srcSliceH,   c-&gt;chrSrcVSubSample);
    int should_dither                = is9_OR_10BPS(c-&gt;srcFormat) ||
                                       is16BPS(c-&gt;srcFormat);
    int lastDstY;

    /* vars which will change and which we need to store back in the context */
    int dstY         = c-&gt;dstY;
    int lumBufIndex  = c-&gt;lumBufIndex;
    int chrBufIndex  = c-&gt;chrBufIndex;
    int lastInLumBuf = c-&gt;lastInLumBuf;
    int lastInChrBuf = c-&gt;lastInChrBuf;

    if (!usePal(c-&gt;srcFormat)) {
        pal = c-&gt;input_rgb2yuv_table;
    }

    if (isPacked(c-&gt;srcFormat)) {
        src[0] =
        src[1] =
        src[2] =
        src[3] = src[0];
        srcStride[0] =
        srcStride[1] =
        srcStride[2] =
        srcStride[3] = srcStride[0];
    }
    srcStride[1] &lt;&lt;= c-&gt;vChrDrop;
    srcStride[2] &lt;&lt;= c-&gt;vChrDrop;

    DEBUG_BUFFERS("swscale() %p[%d] %p[%d] %p[%d] %p[%d] -&gt; %p[%d] %p[%d] %p[%d] %p[%d]\n",
                  src[0], srcStride[0], src[1], srcStride[1],
                  src[2], srcStride[2], src[3], srcStride[3],
                  dst[0], dstStride[0], dst[1], dstStride[1],
                  dst[2], dstStride[2], dst[3], dstStride[3]);
    DEBUG_BUFFERS("srcSliceY: %d srcSliceH: %d dstY: %d dstH: %d\n",
                  srcSliceY, srcSliceH, dstY, dstH);
    DEBUG_BUFFERS("vLumFilterSize: %d vLumBufSize: %d vChrFilterSize: %d vChrBufSize: %d\n",
                  vLumFilterSize, vLumBufSize, vChrFilterSize, vChrBufSize);

    if (dstStride[0]&amp;15 || dstStride[1]&amp;15 ||
        dstStride[2]&amp;15 || dstStride[3]&amp;15) {
        static int warnedAlready = 0; // FIXME maybe move this into the context
        if (flags &amp; SWS_PRINT_INFO &amp;&amp; !warnedAlready) {
            av_log(c, AV_LOG_WARNING,
                   "Warning: dstStride is not aligned!\n"
                   "         -&gt;cannot do aligned memory accesses anymore\n");
            warnedAlready = 1;
        }
    }

    if (   (uintptr_t)dst[0]&amp;15 || (uintptr_t)dst[1]&amp;15 || (uintptr_t)dst[2]&amp;15
        || (uintptr_t)src[0]&amp;15 || (uintptr_t)src[1]&amp;15 || (uintptr_t)src[2]&amp;15
        || dstStride[0]&amp;15 || dstStride[1]&amp;15 || dstStride[2]&amp;15 || dstStride[3]&amp;15
        || srcStride[0]&amp;15 || srcStride[1]&amp;15 || srcStride[2]&amp;15 || srcStride[3]&amp;15
    ) {
        static int warnedAlready=0;
        int cpu_flags = av_get_cpu_flags();
        if (HAVE_MMXEXT &amp;&amp; (cpu_flags &amp; AV_CPU_FLAG_SSE2) &amp;&amp; !warnedAlready){
            av_log(c, AV_LOG_WARNING, "Warning: data is not aligned! This can lead to a speedloss\n");
            warnedAlready=1;
        }
    }

    /* Note the user might start scaling the picture in the middle so this
     * will not get executed. This is not really intended but works
     * currently, so people might do it. */
    if (srcSliceY == 0) {
        lumBufIndex  = -1;
        chrBufIndex  = -1;
        dstY         = 0;
        lastInLumBuf = -1;
        lastInChrBuf = -1;
    }

    if (!should_dither) {
        c-&gt;chrDither8 = c-&gt;lumDither8 = sws_pb_64;
    }
    lastDstY = dstY;
    //逐行循环，一次循环代表处理一行
    //注意dstY和dstH两个变量
    for (; dstY &lt; dstH; dstY++) {
    	//色度的和亮度之间的关系
        const int chrDstY = dstY &gt;&gt; c-&gt;chrDstVSubSample;
        uint8_t *dest[4]  = {
            dst[0] + dstStride[0] * dstY,
            dst[1] + dstStride[1] * chrDstY,
            dst[2] + dstStride[2] * chrDstY,
            (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf) ? dst[3] + dstStride[3] * dstY : NULL,
        };
        int use_mmx_vfilter= c-&gt;use_mmx_vfilter;

        // First line needed as input
        const int firstLumSrcY  = FFMAX(1 - vLumFilterSize, vLumFilterPos[dstY]);
        const int firstLumSrcY2 = FFMAX(1 - vLumFilterSize, vLumFilterPos[FFMIN(dstY | ((1 &lt;&lt; c-&gt;chrDstVSubSample) - 1), dstH - 1)]);
        // First line needed as input
        const int firstChrSrcY  = FFMAX(1 - vChrFilterSize, vChrFilterPos[chrDstY]);

        // Last line needed as input
        int lastLumSrcY  = FFMIN(c-&gt;srcH,    firstLumSrcY  + vLumFilterSize) - 1;
        int lastLumSrcY2 = FFMIN(c-&gt;srcH,    firstLumSrcY2 + vLumFilterSize) - 1;
        int lastChrSrcY  = FFMIN(c-&gt;chrSrcH, firstChrSrcY  + vChrFilterSize) - 1;
        int enough_lines;

        // handle holes (FAST_BILINEAR &amp; weird filters)
        if (firstLumSrcY &gt; lastInLumBuf)
            lastInLumBuf = firstLumSrcY - 1;
        if (firstChrSrcY &gt; lastInChrBuf)
            lastInChrBuf = firstChrSrcY - 1;
        av_assert0(firstLumSrcY &gt;= lastInLumBuf - vLumBufSize + 1);
        av_assert0(firstChrSrcY &gt;= lastInChrBuf - vChrBufSize + 1);

        DEBUG_BUFFERS("dstY: %d\n", dstY);
        DEBUG_BUFFERS("\tfirstLumSrcY: %d lastLumSrcY: %d lastInLumBuf: %d\n",
                      firstLumSrcY, lastLumSrcY, lastInLumBuf);
        DEBUG_BUFFERS("\tfirstChrSrcY: %d lastChrSrcY: %d lastInChrBuf: %d\n",
                      firstChrSrcY, lastChrSrcY, lastInChrBuf);

        // Do we have enough lines in this slice to output the dstY line
        enough_lines = lastLumSrcY2 &lt; srcSliceY + srcSliceH &amp;&amp;
                       lastChrSrcY &lt; FF_CEIL_RSHIFT(srcSliceY + srcSliceH, c-&gt;chrSrcVSubSample);

        if (!enough_lines) {
            lastLumSrcY = srcSliceY + srcSliceH - 1;
            lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1;
            DEBUG_BUFFERS("buffering slice: lastLumSrcY %d lastChrSrcY %d\n",
                          lastLumSrcY, lastChrSrcY);
        }

        // Do horizontal scaling
        //水平拉伸
        //亮度
        while (lastInLumBuf &lt; lastLumSrcY) {
            const uint8_t *src1[4] = {
                src[0] + (lastInLumBuf + 1 - srcSliceY) * srcStride[0],
                src[1] + (lastInLumBuf + 1 - srcSliceY) * srcStride[1],
                src[2] + (lastInLumBuf + 1 - srcSliceY) * srcStride[2],
                src[3] + (lastInLumBuf + 1 - srcSliceY) * srcStride[3],
            };
            lumBufIndex++;
            av_assert0(lumBufIndex &lt; 2 * vLumBufSize);
            av_assert0(lastInLumBuf + 1 - srcSliceY &lt; srcSliceH);
            av_assert0(lastInLumBuf + 1 - srcSliceY &gt;= 0);
            //关键：拉伸
            hyscale(c, lumPixBuf[lumBufIndex], dstW, src1, srcW, lumXInc,
                    hLumFilter, hLumFilterPos, hLumFilterSize,
                    formatConvBuffer, pal, 0);
            if (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf)
                hyscale(c, alpPixBuf[lumBufIndex], dstW, src1, srcW,
                        lumXInc, hLumFilter, hLumFilterPos, hLumFilterSize,
                        formatConvBuffer, pal, 1);
            lastInLumBuf++;
            DEBUG_BUFFERS("\t\tlumBufIndex %d: lastInLumBuf: %d\n",
                          lumBufIndex, lastInLumBuf);
        }
        //水平拉伸
        //色度
        while (lastInChrBuf &lt; lastChrSrcY) {
            const uint8_t *src1[4] = {
                src[0] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[0],
                src[1] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[1],
                src[2] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[2],
                src[3] + (lastInChrBuf + 1 - chrSrcSliceY) * srcStride[3],
            };
            chrBufIndex++;
            av_assert0(chrBufIndex &lt; 2 * vChrBufSize);
            av_assert0(lastInChrBuf + 1 - chrSrcSliceY &lt; (chrSrcSliceH));
            av_assert0(lastInChrBuf + 1 - chrSrcSliceY &gt;= 0);
            // FIXME replace parameters through context struct (some at least)
            //关键：拉伸
            if (c-&gt;needs_hcscale)
                hcscale(c, chrUPixBuf[chrBufIndex], chrVPixBuf[chrBufIndex],
                        chrDstW, src1, chrSrcW, chrXInc,
                        hChrFilter, hChrFilterPos, hChrFilterSize,
                        formatConvBuffer, pal);
            lastInChrBuf++;
            DEBUG_BUFFERS("\t\tchrBufIndex %d: lastInChrBuf: %d\n",
                          chrBufIndex, lastInChrBuf);
        }
        // wrap buf index around to stay inside the ring buffer
        if (lumBufIndex &gt;= vLumBufSize)
            lumBufIndex -= vLumBufSize;
        if (chrBufIndex &gt;= vChrBufSize)
            chrBufIndex -= vChrBufSize;
        if (!enough_lines)
            break;  // we can't output a dstY line so let's try with the next slice

#if HAVE_MMX_INLINE
        updateMMXDitherTables(c, dstY, lumBufIndex, chrBufIndex,
                              lastInLumBuf, lastInChrBuf);
#endif
        if (should_dither) {
            c-&gt;chrDither8 = ff_dither_8x8_128[chrDstY &amp; 7];
            c-&gt;lumDither8 = ff_dither_8x8_128[dstY    &amp; 7];
        }
        if (dstY &gt;= dstH - 2) {
            /* hmm looks like we can't use MMX here without overwriting
             * this array's tail */
            ff_sws_init_output_funcs(c, &amp;yuv2plane1, &amp;yuv2planeX, &amp;yuv2nv12cX,
                                     &amp;yuv2packed1, &amp;yuv2packed2, &amp;yuv2packedX, &amp;yuv2anyX);
            use_mmx_vfilter= 0;
        }

        {
            const int16_t **lumSrcPtr  = (const int16_t **)(void*) lumPixBuf  + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;
            const int16_t **chrUSrcPtr = (const int16_t **)(void*) chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;
            const int16_t **chrVSrcPtr = (const int16_t **)(void*) chrVPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;
            const int16_t **alpSrcPtr  = (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf) ?
                                         (const int16_t **)(void*) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;
            int16_t *vLumFilter = c-&gt;vLumFilter;
            int16_t *vChrFilter = c-&gt;vChrFilter;

            if (isPlanarYUV(dstFormat) ||
                (isGray(dstFormat) &amp;&amp; !isALPHA(dstFormat))) { // YV12 like
                const int chrSkipMask = (1 &lt;&lt; c-&gt;chrDstVSubSample) - 1;

                vLumFilter +=    dstY * vLumFilterSize;
                vChrFilter += chrDstY * vChrFilterSize;

//                 av_assert0(use_mmx_vfilter != (
//                                yuv2planeX == yuv2planeX_10BE_c
//                             || yuv2planeX == yuv2planeX_10LE_c
//                             || yuv2planeX == yuv2planeX_9BE_c
//                             || yuv2planeX == yuv2planeX_9LE_c
//                             || yuv2planeX == yuv2planeX_16BE_c
//                             || yuv2planeX == yuv2planeX_16LE_c
//                             || yuv2planeX == yuv2planeX_8_c) || !ARCH_X86);

                if(use_mmx_vfilter){
                    vLumFilter= (int16_t *)c-&gt;lumMmxFilter;
                    vChrFilter= (int16_t *)c-&gt;chrMmxFilter;
                }
                //输出一行水平拉伸过的像素
                //亮度
                //是否垂直拉伸？
                if (vLumFilterSize == 1) {
                	//亮度-不垂直拉伸-分量模式（planar）-输出一行水平拉伸的像素
                    yuv2plane1(lumSrcPtr[0], dest[0], dstW, c-&gt;lumDither8, 0);
                } else {
                	//亮度-垂直拉伸-分量模式（planar）-输出一行水平拉伸的像素
                    yuv2planeX(vLumFilter, vLumFilterSize,
                               lumSrcPtr, dest[0],
                               dstW, c-&gt;lumDither8, 0);
                }
                //色度
                //是否垂直拉伸？
                if (!((dstY &amp; chrSkipMask) || isGray(dstFormat))) {
                    if (yuv2nv12cX) {
                        yuv2nv12cX(c, vChrFilter,
                                   vChrFilterSize, chrUSrcPtr, chrVSrcPtr,
                                   dest[1], chrDstW);
                    } else if (vChrFilterSize == 1) {
                    	//色度-不垂直拉伸-分量模式（planar）-输出一行水平拉伸的像素
                    	//注意是2个分量
                        yuv2plane1(chrUSrcPtr[0], dest[1], chrDstW, c-&gt;chrDither8, 0);
                        yuv2plane1(chrVSrcPtr[0], dest[2], chrDstW, c-&gt;chrDither8, 3);
                    } else {
                    	//色度-垂直拉伸-分量模式（planar）-输出一行水平拉伸的像素
                    	//注意是2个分量
                        yuv2planeX(vChrFilter,
                                   vChrFilterSize, chrUSrcPtr, dest[1],
                                   chrDstW, c-&gt;chrDither8, 0);
                        yuv2planeX(vChrFilter,
                                   vChrFilterSize, chrVSrcPtr, dest[2],
                                   chrDstW, c-&gt;chrDither8, use_mmx_vfilter ? (c-&gt;uv_offx2 &gt;&gt; 1) : 3);
                    }
                }

                if (CONFIG_SWSCALE_ALPHA &amp;&amp; alpPixBuf) {
                    if(use_mmx_vfilter){
                        vLumFilter= (int16_t *)c-&gt;alpMmxFilter;
                    }
                    if (vLumFilterSize == 1) {
                        yuv2plane1(alpSrcPtr[0], dest[3], dstW,
                                   c-&gt;lumDither8, 0);
                    } else {
                        yuv2planeX(vLumFilter,
                                   vLumFilterSize, alpSrcPtr, dest[3],
                                   dstW, c-&gt;lumDither8, 0);
                    }
                }
            } else if (yuv2packedX) {
                av_assert1(lumSrcPtr  + vLumFilterSize - 1 &lt; (const int16_t **)lumPixBuf  + vLumBufSize * 2);
                av_assert1(chrUSrcPtr + vChrFilterSize - 1 &lt; (const int16_t **)chrUPixBuf + vChrBufSize * 2);
                if (c-&gt;yuv2packed1 &amp;&amp; vLumFilterSize == 1 &amp;&amp;
                    vChrFilterSize &lt;= 2) { // unscaled RGB
                    int chrAlpha = vChrFilterSize == 1 ? 0 : vChrFilter[2 * dstY + 1];
                	//不垂直拉伸-打包模式（packed）-输出一行水平拉伸的像素
                    yuv2packed1(c, *lumSrcPtr, chrUSrcPtr, chrVSrcPtr,
                                alpPixBuf ? *alpSrcPtr : NULL,
                                dest[0], dstW, chrAlpha, dstY);
                } else if (c-&gt;yuv2packed2 &amp;&amp; vLumFilterSize == 2 &amp;&amp;
                           vChrFilterSize == 2) { // bilinear upscale RGB
                    int lumAlpha = vLumFilter[2 * dstY + 1];
                    int chrAlpha = vChrFilter[2 * dstY + 1];
                    lumMmxFilter[2] =
                    lumMmxFilter[3] = vLumFilter[2 * dstY]    * 0x10001;
                    chrMmxFilter[2] =
                    chrMmxFilter[3] = vChrFilter[2 * chrDstY] * 0x10001;
                    yuv2packed2(c, lumSrcPtr, chrUSrcPtr, chrVSrcPtr,
                                alpPixBuf ? alpSrcPtr : NULL,
                                dest[0], dstW, lumAlpha, chrAlpha, dstY);
                } else { // general RGB
                	//垂直拉伸-打包模式（packed）-输出一行水平拉伸的像素
                    yuv2packedX(c, vLumFilter + dstY * vLumFilterSize,
                                lumSrcPtr, vLumFilterSize,
                                vChrFilter + dstY * vChrFilterSize,
                                chrUSrcPtr, chrVSrcPtr, vChrFilterSize,
                                alpSrcPtr, dest[0], dstW, dstY);
                }
            } else {
                av_assert1(!yuv2packed1 &amp;&amp; !yuv2packed2);
                yuv2anyX(c, vLumFilter + dstY * vLumFilterSize,
                         lumSrcPtr, vLumFilterSize,
                         vChrFilter + dstY * vChrFilterSize,
                         chrUSrcPtr, chrVSrcPtr, vChrFilterSize,
                         alpSrcPtr, dest, dstW, dstY);
            }
        }
    }
    if (isPlanar(dstFormat) &amp;&amp; isALPHA(dstFormat) &amp;&amp; !alpPixBuf) {
        int length = dstW;
        int height = dstY - lastDstY;

        if (is16BPS(dstFormat) || isNBPS(dstFormat)) {
            const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(dstFormat);
            fillPlane16(dst[3], dstStride[3], length, height, lastDstY,
                    1, desc-&gt;comp[3].depth_minus1,
                    isBE(dstFormat));
        } else
            fillPlane(dst[3], dstStride[3], length, height, lastDstY, 255);
    }

#if HAVE_MMXEXT_INLINE
    if (av_get_cpu_flags() &amp; AV_CPU_FLAG_MMXEXT)
        __asm__ volatile ("sfence" ::: "memory");
#endif
    emms_c();

    /* store changed local vars back in the context */
    c-&gt;dstY         = dstY;
    c-&gt;lumBufIndex  = lumBufIndex;
    c-&gt;chrBufIndex  = chrBufIndex;
    c-&gt;lastInLumBuf = lastInLumBuf;
    c-&gt;lastInChrBuf = lastInChrBuf;

    return dstY - lastDstY;
}
</pre>
    <br/>
    <br/>
    可以看出swscale()是一行一行的进行图像缩放工作的。其中每行数据的处理按照“先水平拉伸，然后垂直拉伸”的方式进行处理。具体的实现函数如下所示：
    <br/>
    <p>
    </p>
    1.
    <span style="white-space: pre;">
    </span>
    水平拉伸
    <br/>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <p>
      a)
      <span style="white-space:pre">
      </span>
      亮度水平拉伸：hyscale()
     </p>
     <p>
      b)
      <span style="white-space:pre">
      </span>
      色度水平拉伸：hcscale()
     </p>
    </blockquote>
    <p>
     2.
     <span style="white-space:pre">
     </span>
     垂直拉伸
    </p>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <p>
      a)
      <span style="white-space:pre">
      </span>
      Planar
     </p>
    </blockquote>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
      <p>
       i.
       <span style="white-space:pre">
       </span>
       亮度垂直拉伸-不拉伸：yuv2plane1()
      </p>
     </blockquote>
     <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
      <p>
       ii.
       <span style="white-space:pre">
       </span>
       亮度垂直拉伸-拉伸：yuv2planeX()
      </p>
     </blockquote>
     <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
      <p>
       iii.
       <span style="white-space:pre">
       </span>
       色度垂直拉伸-不拉伸：yuv2plane1()
      </p>
     </blockquote>
     <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
      <p>
       iv.
       <span style="white-space:pre">
       </span>
       色度垂直拉伸-拉伸：yuv2planeX()
      </p>
     </blockquote>
    </blockquote>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <p>
      b)
      <span style="white-space:pre">
      </span>
      Packed
     </p>
    </blockquote>
    <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
     <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
      <p>
       i.
       <span style="white-space:pre">
       </span>
       垂直拉伸-不拉伸：yuv2packed1()
      </p>
     </blockquote>
     <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
      <p>
       ii.
       <span style="white-space:pre">
       </span>
       垂直拉伸-拉伸：yuv2packedX()
      </p>
     </blockquote>
    </blockquote>
    <p>
     下面具体看看这几个函数的定义。
     <br/>
     <br/>
    </p>
    <h3>
     hyscale()
    </h3>
    水平亮度拉伸函数hyscale()的定义位于libswscale\swscale.c，如下所示。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_10_8156669">// *** horizontal scale Y line to temp buffer
static av_always_inline void hyscale(SwsContext *c, int16_t *dst, int dstWidth,
                                     const uint8_t *src_in[4],
                                     int srcW, int xInc,
                                     const int16_t *hLumFilter,
                                     const int32_t *hLumFilterPos,
                                     int hLumFilterSize,
                                     uint8_t *formatConvBuffer,
                                     uint32_t *pal, int isAlpha)
{
    void (*toYV12)(uint8_t *, const uint8_t *, const uint8_t *, const uint8_t *, int, uint32_t *) =
        isAlpha ? c-&gt;alpToYV12 : c-&gt;lumToYV12;
    void (*convertRange)(int16_t *, int) = isAlpha ? NULL : c-&gt;lumConvertRange;
    const uint8_t *src = src_in[isAlpha ? 3 : 0];

    if (toYV12) {
        toYV12(formatConvBuffer, src, src_in[1], src_in[2], srcW, pal);
        src = formatConvBuffer;
    } else if (c-&gt;readLumPlanar &amp;&amp; !isAlpha) {
    	//读取
        c-&gt;readLumPlanar(formatConvBuffer, src_in, srcW, c-&gt;input_rgb2yuv_table);
        //赋值
        src = formatConvBuffer;
    } else if (c-&gt;readAlpPlanar &amp;&amp; isAlpha) {
        c-&gt;readAlpPlanar(formatConvBuffer, src_in, srcW, NULL);
        src = formatConvBuffer;
    }

    if (!c-&gt;hyscale_fast) {
    	//亮度-水平拉伸
        c-&gt;hyScale(c, dst, dstWidth, src, hLumFilter,
                   hLumFilterPos, hLumFilterSize);
    } else { // fast bilinear upscale / crap downscale
        c-&gt;hyscale_fast(c, dst, dstWidth, src, srcW, xInc);
    }
    //如果需要取值范围的转换（0-255和16-235之间）
    if (convertRange)
        convertRange(dst, dstWidth);
}
</pre>
    <br/>
    从hyscale()的源代码可以看出，它的流程如下所示。
    <br/>
    <strong>
     1.转换成Y（亮度）
    </strong>
    <br/>
    如果SwsContext的toYV12()函数存在，调用用该函数将数据转换为Y。如果该函数不存在，则调用SwsContext的readLumPlanar()读取Y。
    <br/>
    <strong>
     2.拉伸
    </strong>
    <br/>
    拉伸通过SwsContext的hyScale ()函数完成。如果存在hyscale_fast()方法的话，系统会优先调用hyscale_fast()。
    <br/>
    <strong>
     3.转换范围（如果需要的话）
    </strong>
    <br/>
    如果需要转换亮度的取值范围（例如需要进行16-235的MPEG标准与0-255的JPEG标准之间的转换），则会调用SwsContext的lumConvertRange ()函数。
    <br/>
    上述几个步骤的涉及到的函数在上一篇文章中几经介绍过了，在这里重复一下。
    <p>
    </p>
    <p>
     <br/>
    </p>
    <h4>
     toYV12() [SwsContext -&gt;lumToYV12()]
    </h4>
    toYV12()的实现函数是在ff_sws_init_input_funcs()中初始化的。在这里举几种具体的输入像素格式。
    <p>
    </p>
    <p>
     <br/>
     <strong>
      输入格式为YUYV422/ YVYU422
     </strong>
     <br/>
     ff_sws_init_input_funcs()中，输入像素格式为YUYV422/ YVYU422的时候，toYV12()指向yuy2ToY_c()函数。源代码如下所示。
     <br/>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_11_1763187">    case AV_PIX_FMT_YUYV422:
    case AV_PIX_FMT_YVYU422:
    case AV_PIX_FMT_YA8:
        c-&gt;lumToYV12 = yuy2ToY_c;
        break;</pre>
    yuy2ToY_c()的定义如下所示。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_12_3351817">static void yuy2ToY_c(uint8_t *dst, const uint8_t *src, const uint8_t *unused1, const uint8_t *unused2,  int width,
                      uint32_t *unused)
{
    int i;
    for (i = 0; i &lt; width; i++)
        dst[i] = src[2 * i];
}</pre>
    从yuy2ToY_c()的定义可以看出，该函数取出了所有的Y值（Y值在src[]数组中的下标为偶数）。
    <br/>
    <br/>
    <br/>
    <strong>
     输入格式为RGB24
    </strong>
    <br/>
    ff_sws_init_input_funcs()中，输入像素格式为RGB24的时候，toYV12()指向yuy2ToY_c()函数。源代码如下所示。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_13_2149568">    case AV_PIX_FMT_RGB24:
        c-&gt;lumToYV12 = rgb24ToY_c;
        break;</pre>
    rgb24ToY_c()的定义如下所示。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_14_3214810">static void rgb24ToY_c(uint8_t *_dst, const uint8_t *src, const uint8_t *unused1, const uint8_t *unused2, int width,
                       uint32_t *rgb2yuv)
{
    int16_t *dst = (int16_t *)_dst;
    int32_t ry = rgb2yuv[RY_IDX], gy = rgb2yuv[GY_IDX], by = rgb2yuv[BY_IDX];
    int i;
    for (i = 0; i &lt; width; i++) {
        int r = src[i * 3 + 0];
        int g = src[i * 3 + 1];
        int b = src[i * 3 + 2];

        dst[i] = ((ry*r + gy*g + by*b + (32&lt;&lt;(RGB2YUV_SHIFT-1)) + (1&lt;&lt;(RGB2YUV_SHIFT-7)))&gt;&gt;(RGB2YUV_SHIFT-6));
    }
}</pre>
    从rgb24ToY_c()的定义可以看出，该函数通过R、G、B三个元素计算Y的值。其中R、G、B的系数取自于数组rgb2yuv[]（这个地方还没有研究）；RGB2YUV_SHIFT似乎代表了转换后YUV的位数，取值为15（这个地方也还没有深入看）。
    <br/>
    <br/>
    <br/>
    <h4>
     SwsContext -&gt; hyScale ()
    </h4>
    SwsContext -&gt; hyScale ()的实现函数是在sws_init_swscale ()中初始化的。可以回顾一下sws_init_swscale ()的定义，如下所示。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_15_1489173">static av_cold void sws_init_swscale(SwsContext *c)
{
    enum AVPixelFormat srcFormat = c-&gt;srcFormat;

    ff_sws_init_output_funcs(c, &amp;c-&gt;yuv2plane1, &amp;c-&gt;yuv2planeX,
                             &amp;c-&gt;yuv2nv12cX, &amp;c-&gt;yuv2packed1,
                             &amp;c-&gt;yuv2packed2, &amp;c-&gt;yuv2packedX, &amp;c-&gt;yuv2anyX);

    ff_sws_init_input_funcs(c);


    if (c-&gt;srcBpc == 8) {
        if (c-&gt;dstBpc &lt;= 14) {
            c-&gt;hyScale = c-&gt;hcScale = hScale8To15_c;
            if (c-&gt;flags &amp; SWS_FAST_BILINEAR) {
                c-&gt;hyscale_fast = ff_hyscale_fast_c;
                c-&gt;hcscale_fast = ff_hcscale_fast_c;
            }
        } else {
            c-&gt;hyScale = c-&gt;hcScale = hScale8To19_c;
        }
    } else {
        c-&gt;hyScale = c-&gt;hcScale = c-&gt;dstBpc &gt; 14 ? hScale16To19_c
                                                 : hScale16To15_c;
    }

    ff_sws_init_range_convert(c);

    if (!(isGray(srcFormat) || isGray(c-&gt;dstFormat) ||
          srcFormat == AV_PIX_FMT_MONOBLACK || srcFormat == AV_PIX_FMT_MONOWHITE))
        c-&gt;needs_hcscale = 1;
}
</pre>
    <br/>
    从sws_init_swscale ()的定义可以看出，ff_sws_init_input_funcs()和ff_sws_init_range_convert()之间的代码完成了hyScale()的初始化。根据srcBpc和dstBpc取值的不同，有几种不同的拉伸函数。根据我的理解，srcBpc代表了输入的每个像素单个分量的位数，dstBpc代表了输出的每个像素单个分量的位数。最常见的像素单个分量的位数是8位。从代码中可以看出，在输入像素单个分量的位数为8位，而且输出像素单个分量的位数也为8位的时候，SwsContext 的 hyScale ()会指向hScale8To15_c()函数。
    <p>
    </p>
    <p>
     <br/>
    </p>
    <h4>
     hScale8To15_c()
    </h4>
    <p>
    </p>
    <p>
     hScale8To15_c()的定义如下所示。有关这个方面的代码还没有详细研究，日后再作补充。
     <br/>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_16_9522772">// bilinear / bicubic scaling
static void hScale8To15_c(SwsContext *c, int16_t *dst, int dstW,
                          const uint8_t *src, const int16_t *filter,
                          const int32_t *filterPos, int filterSize)
{
    int i;
    for (i = 0; i &lt; dstW; i++) {
        int j;
        int srcPos = filterPos[i];
        int val    = 0;
        for (j = 0; j &lt; filterSize; j++) {
            val += ((int)src[srcPos + j]) * filter[filterSize * i + j];
        }
        dst[i] = FFMIN(val &gt;&gt; 7, (1 &lt;&lt; 15) - 1); // the cubic equation does overflow ...
    }
}</pre>
    <br/>
    <h4>
     lumConvertRange () [SwsContext -&gt; lumConvertRange()]
    </h4>
    <p>
    </p>
    <p>
     SwsContext -&gt; hyScale ()的实现函数是在ff_sws_init_range_convert()中初始化的。可以回顾一下ff_sws_init_range_convert ()的定义，如下所示。
     <br/>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_17_5812268">av_cold void ff_sws_init_range_convert(SwsContext *c)
{
    c-&gt;lumConvertRange = NULL;
    c-&gt;chrConvertRange = NULL;
    if (c-&gt;srcRange != c-&gt;dstRange &amp;&amp; !isAnyRGB(c-&gt;dstFormat)) {
        if (c-&gt;dstBpc &lt;= 14) {
            if (c-&gt;srcRange) {
                c-&gt;lumConvertRange = lumRangeFromJpeg_c;
                c-&gt;chrConvertRange = chrRangeFromJpeg_c;
            } else {
                c-&gt;lumConvertRange = lumRangeToJpeg_c;
                c-&gt;chrConvertRange = chrRangeToJpeg_c;
            }
        } else {
            if (c-&gt;srcRange) {
                c-&gt;lumConvertRange = lumRangeFromJpeg16_c;
                c-&gt;chrConvertRange = chrRangeFromJpeg16_c;
            } else {
                c-&gt;lumConvertRange = lumRangeToJpeg16_c;
                c-&gt;chrConvertRange = chrRangeToJpeg16_c;
            }
        }
    }
}</pre>
    <br/>
    SwsContext 的lumConvertRange()函数主要用于JPEG标准像素取值范围（0-255）和MPEG标准像素取值范围（16-235）之间的转换。有关这方面的分析在上一篇文章中一斤详细叙述过，在这里不再重复。简单看一下其中的一个函数。
    <p>
    </p>
    <p>
     <br/>
    </p>
    <h4>
     lumRangeFromJpeg_c()
    </h4>
    <p>
     把亮度从JPEG标准转换为MPEG标准（0-255转换为16-235）的函数lumRangeFromJpeg_c()的定义如下所示。
    </p>
    <p>
    </p>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_18_465562">static void lumRangeFromJpeg_c(int16_t *dst, int width)
{
    int i;
    for (i = 0; i &lt; width; i++)
        dst[i] = (dst[i] * 14071 + 33561947) &gt;&gt; 14;
}</pre>
    其实这个函数就是做了一个（0-255）到（16-235）的映射。它将亮度值“0”映射成“16”，“255”映射成“235”，因此我们可以代入一个“255”看看转换后的数值是否为“235”。在这里需要注意，dst中存储的像素数值是15bit的亮度值。因此我们需要将8bit的数值“255”左移7位后带入。经过计算，255左移7位后取值为32640，计算后得到的数值为30080，右移7位后得到的8bit亮度值即为235。
    <br/>
    <br/>
    <h3>
     hcscale()
    </h3>
    水平色度拉伸函数hcscale()的定义位于libswscale\swscale.c，如下所示。
    <br/>
    <pre class="cpp" code_snippet_id="621825" name="code" snippet_file_name="blog_20150317_19_2054192">static av_always_inline void hcscale(SwsContext *c, int16_t *dst1,
                                     int16_t *dst2, int dstWidth,
                                     const uint8_t *src_in[4],
                                     int srcW, int xInc,
                                     const int16_t *hChrFilter,
                                     const int32_t *hChrFilterPos,
                                     int hChrFilterSize,
                                     uint8_t *formatConvBuffer, uint32_t *pal)
{
    const uint8_t *src1 = src_in[1], *src2 = src_in[2];
    if (c-&gt;chrToYV12) {
        uint8_t *buf2 = formatConvBuffer +
                        FFALIGN(srcW*2+78, 16);
        //转换
        c-&gt;chrToYV12(formatConvBuffer, buf2, src_in[0], src1, src2, srcW, pal);
        src1= formatConvBuffer;
        src2= buf2;
    } else if (c-&gt;readChrPlanar) {
        uint8_t *buf2 = formatConvBuffer +
                        FFALIGN(srcW*2+78, 16);
        //读取
        c-&gt;readChrPlanar(formatConvBuffer, buf2, src_in, srcW, c-&gt;input_rgb2yuv_table);
        //赋值
        src1 = formatConvBuffer;
        src2 = buf2;
    }

    if (!c-&gt;hcscale_fast) {
    	//色度-水平拉伸
        c-&gt;hcScale(c, dst1, dstWidth, src1, hChrFilter, hChrFilterPos, hChrFilterSize);
        c-&gt;hcScale(c, dst2, dstWidth, src2, hChrFilter, hChrFilterPos, hChrFilterSize);
    } else { // fast bilinear upscale / crap downscale
        c-&gt;hcscale_fast(c, dst1, dst2, dstWidth, src1, src2, srcW, xInc);
    }
    //如果需要取值范围的转换（0-255和16-235之间）
    if (c-&gt;chrConvertRange)
        c-&gt;chrConvertRange(dst1, dst2, dstWidth);
}</pre>
    <br/>
    从hcscale()的源代码可以看出，它的流程如下所示。
    <br/>
    <strong>
     1.转换成UV
    </strong>
    <br/>
    该功能通过SwsContext的chrToYV12 ()函数完成。如果该函数不存在，则调用SwsContext的readChrPlanar ()读取UV。
    <p>
    </p>
    <p>
     <strong>
      2.拉伸
     </strong>
     <br/>
     拉伸通过SwsContext的hcScale ()函数完成。如果存在hcscale_fast()方法的话，系统会优先调用hcscale_fast ()。
    </p>
    <p>
     <strong>
      3.转换范围（如果需要的话）
     </strong>
     <br/>
     如果需要转换色度的取值范围（例如色度取值范围从0-255转换为16-240），则会调用SwsContext的chrConvertRange ()函数。
    </p>
    <p>
     hcscale()的原理和hyScale ()的原理基本上是一样的，在这里既不再详细研究了。
     <br/>
     <br/>
     <br/>
     还有几个函数没有分析，但是时间有限，以后有机会再进行补充。
     <br/>
     <br/>
     <br/>
     <br/>
     <strong>
      <span style="color:#990000;">
       雷霄骅
       <br/>
       leixiaohua1020@126.com
       <br/>
       http://blog.csdn.net/leixiaohua1020
      </span>
     </strong>
     <br/>
     <br/>
     <br/>
     <br/>
     <br/>
     <br/>
     <br/>
     <br/>
     <br/>
    </p>
   </div>
  </div>
  <div style="display:none;" class="hide-article-box text-center csdn-tracking-statistics tracking-click" data-mod="popu_376">
   <a class="btn btn-red-hollow" id="btn-readmore">
    阅读更多
   </a>
  </div>
 </article>
 <div class="article-bar-bottom">
  <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许不得转载。			https://blog.csdn.net/leixiaohua1020/article/details/44346687
  </div>
  <div class="tags-box artic-tag-box">
   <span class="label">
    文章标签：
   </span>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=FFmpeg&amp;t=blog" target="_blank">
    FFmpeg
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=swscale&amp;t=blog" target="_blank">
    swscale
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=YUV&amp;t=blog" target="_blank">
    YUV
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=RGB&amp;t=blog" target="_blank">
    RGB
   </a>
   <a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=源代码&amp;t=blog" target="_blank">
    源代码
   </a>
  </div>
  <div class="tags-box">
   <span class="label">
    个人分类：
   </span>
   <a class="tag-link" href="https://blog.csdn.net/leixiaohua1020/article/category/1360795" target="_blank">
    FFMPEG
   </a>
  </div>
  <div class="tags-box">
   <span class="label">
    所属专栏：
   </span>
   <a class="tag-link" href="https://blog.csdn.net/column/details/ffmpeg-devel.html" target="_blank">
    FFmpeg
   </a>
  </div>
 </div>
 <!-- !empty($pre_next_article[0]) -->
</div>
<div class="recommend-box">
                            <div style="background: #fff; border: dashed 1px #666; padding-left: 1em; padding-top: 1em; padding-bottom: 1em;">
                                <span style="font-size: 0.8em; font-weight: bold;">
                                    此PDF由<a style="color:#0000ff" href="http://www.github.com/spygg"  target="_blank">spygg</a>生成,请尊重原作者版权!!!
                                    <br/>
                                    我的邮箱:liushidc@163.com
                                </span>
                                </div> 
                        </div>
                    </main>
      
                </div>

            <script>
                var recommendCount = 0;
                var articleTit = "";
                var articleId = "";
                var commentscount = 0;

                //1禁止评论，2正常
                var commentAuth = 1;
                //百度搜索
                var baiduKey = "";
                var needInsertBaidu = "";
            </script>
            <script src="https://csdnimg.cn/release/phoenix/template/js/detail-effe72036e.min.js"></script>
            </body>
        </html>